{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "03-logistic-regression.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "u4r68b9pZesP",
        "pn3_BsUVZesR"
      ],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b12df51a0b1c4d249d8ba90f7c44a754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_65c906d5736d4222b0f0426159e3e959",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4aa369f8101643148c55d06693d16c1e",
              "IPY_MODEL_eb357f5fc2b24029a7b422f54be5c6f3"
            ]
          }
        },
        "65c906d5736d4222b0f0426159e3e959": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4aa369f8101643148c55d06693d16c1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_57795e62409d4f03a35a550080698ff6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac1f9901ff6d4e49b762b40d8a194819"
          }
        },
        "eb357f5fc2b24029a7b422f54be5c6f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f12d8424845a4e428b5e248932f00aa2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9920512/? [00:03&lt;00:00, 3159716.75it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b59023b08ee4b2e9d8ee1e363fe27b8"
          }
        },
        "57795e62409d4f03a35a550080698ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac1f9901ff6d4e49b762b40d8a194819": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f12d8424845a4e428b5e248932f00aa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b59023b08ee4b2e9d8ee1e363fe27b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c129edc1016649deb6d21c0d7dc48ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8ec4916e32db49b593e52f457e4d0704",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_228502e9e4fa4ae28a5e9f6919bca321",
              "IPY_MODEL_bc57f0ac4bbc40ab9f3ceec5edf60d2a"
            ]
          }
        },
        "8ec4916e32db49b593e52f457e4d0704": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "228502e9e4fa4ae28a5e9f6919bca321": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a6157cacc3084fd8a567a370326fbc61",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ecdfe475a1ae4730924be4f8e0a7cf01"
          }
        },
        "bc57f0ac4bbc40ab9f3ceec5edf60d2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_292ad33fd4574bb790f7c9ef6733e227",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 32768/? [00:00&lt;00:00, 103217.04it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9f8e73032175419784dd351ff97231c7"
          }
        },
        "a6157cacc3084fd8a567a370326fbc61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ecdfe475a1ae4730924be4f8e0a7cf01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "292ad33fd4574bb790f7c9ef6733e227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9f8e73032175419784dd351ff97231c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "09ff81e6939447668d5676ea6dd0df61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_450785243fba40beace70eb638dd8116",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eb7a63629bf14bfdb069ef64d4d0f7a8",
              "IPY_MODEL_0569606510014b118a1ff8e26b505a33"
            ]
          }
        },
        "450785243fba40beace70eb638dd8116": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eb7a63629bf14bfdb069ef64d4d0f7a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_49388a787a1c47468e9c09525202f58f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_afa7211f74744c42ae98895065d9dab7"
          }
        },
        "0569606510014b118a1ff8e26b505a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_171f23a5dfe2480fb7163412b9f36ca2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1654784/? [00:01&lt;00:00, 1349850.06it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_26f4c6bb701d4572a3ffab7ccc04b253"
          }
        },
        "49388a787a1c47468e9c09525202f58f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "afa7211f74744c42ae98895065d9dab7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "171f23a5dfe2480fb7163412b9f36ca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "26f4c6bb701d4572a3ffab7ccc04b253": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ef925594bd14fbbabd6d53ab07c825e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_70b9b71dceb643dfa7bf74a8bcb64ad6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_29bc5ff73c8943a8bd546ebcaf862826",
              "IPY_MODEL_b3dcea380d284d159b49ea53a170a4c8"
            ]
          }
        },
        "70b9b71dceb643dfa7bf74a8bcb64ad6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29bc5ff73c8943a8bd546ebcaf862826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cc03b7d2d54e48b69cce60418535fa9c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4be037f64a38428c8ab0421d9dcb6c55"
          }
        },
        "b3dcea380d284d159b49ea53a170a4c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_da149dc42cda428299361bbec7fcbff1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8192/? [00:00&lt;00:00, 18570.37it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e9510c7aeaaf403b950cf9ab0f6ad714"
          }
        },
        "cc03b7d2d54e48b69cce60418535fa9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4be037f64a38428c8ab0421d9dcb6c55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "da149dc42cda428299361bbec7fcbff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e9510c7aeaaf403b950cf9ab0f6ad714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB2nezNrZeqS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "441fa070-124c-4a44-d0fb-a723d6691b13"
      },
      "source": [
        "# Jovian Commit Essentials\n",
        "# Please retain and execute this cell without modifying the contents for `jovian.commit` to work\n",
        "!pip install jovian --upgrade -q\n",
        "import jovian\n",
        "jovian.utils.colab.set_colab_file_id('1PPvIkrgrg3HFmut4q0Ze5Rm9TcF_jqNf')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█████                           | 10kB 19.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 30kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 40kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 51kB 3.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.6MB/s \n",
            "\u001b[?25h  Building wheel for uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW6d1Vo5ZeqV",
        "colab_type": "text"
      },
      "source": [
        "# Image Classification using Logistic Regression in PyTorch\n",
        "\n",
        "#### Part 3 of \"PyTorch: Zero to GANs\"\n",
        "\n",
        "*This post is the third in a series of tutorials on building deep learning models with PyTorch, an open source neural networks library. Check out the full series:*\n",
        "\n",
        "1. [PyTorch Basics: Tensors & Gradients](https://jovian.ml/aakashns/01-pytorch-basics)\n",
        "2. [Linear Regression & Gradient Descent](https://jovian.ml/aakashns/02-linear-regression)\n",
        "3. [Image Classfication using Logistic Regression](https://jovian.ml/aakashns/03-logistic-regression) \n",
        "4. [Training Deep Neural Networks on a GPU](https://jovian.ml/aakashns/04-feedforward-nn)\n",
        "5. [Image Classification using Convolutional Neural Networks](https://jovian.ml/aakashns/05-cifar10-cnn)\n",
        "6. [Data Augmentation, Regularization and ResNets](https://jovian.ml/aakashns/05b-cifar10-resnet)\n",
        "7. [Generating Images using Generative Adverserial Networks](https://jovian.ml/aakashns/06-mnist-gan)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmh9vgSWZeqW",
        "colab_type": "text"
      },
      "source": [
        "In this tutorial, we'll use our existing knowledge of PyTorch and linear regression to solve a very different kind of problem: *image classification*. We'll use the famous [*MNIST Handwritten Digits Database*](http://yann.lecun.com/exdb/mnist/) as our training dataset. It consists of 28px by 28px grayscale images of handwritten digits (0 to 9), along with labels for each image indicating which digit it represents. Here are some sample images from the dataset:\n",
        "\n",
        "![mnist-sample](https://i.imgur.com/CAYnuo1.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1piWUr7ZeqW",
        "colab_type": "text"
      },
      "source": [
        "## System setup\n",
        "\n",
        "This tutorial takes a code-first approach towards learning PyTorch, and you should try to follow along by running and experimenting with the code yourself. The easiest way to start executing this notebook is to click the **\"Run\"** button at the top of this page, and select **\"Run on Kaggle\"**. This will run the notebook on Kaggle, a free online service for running Jupyter notebooks (you might need to create an account).\n",
        "\n",
        "### Running on your computer locally\n",
        "*(Skip this if you're running on Kaggle)* To run this notebook locally, clone this notebook, install the required dependencies using [conda](https://conda.io/en/latest/), and start Jupyter by running the following commands on the terminal / Conda prompt:\n",
        "\n",
        "```bash\n",
        "pip install jovian --upgrade                      # Install the jovian library \n",
        "jovian clone aakashns/03-logistic-regression      # Download notebook & dependencies\n",
        "cd 03-logistic-regression                         # Enter the created directory \n",
        "conda create -n 03-logistic-regression python=3.8 # Create an environment\n",
        "conda activate 03-logistic-regression             # Activate virtual env\n",
        "jupyter notebook                                  # Start Jupyter\n",
        "```\n",
        "\n",
        "You can find the `notebook_id` by cliking the *Clone* button at the top of this page on Jovian. For a more detailed explanation of the above steps, check out the *System setup* section in the [first notebook](https://jovian.ml/aakashns/01-pytorch-basics).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1TuTz-sZeqX",
        "colab_type": "text"
      },
      "source": [
        "## Exploring the Data\n",
        "\n",
        "We begin by importing `torch` and `torchvision`. `torchvision` contains some utilities for working with image data. It also contains helper classes to automatically download and import popular datasets like MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJuffaxwZeqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Uncomment and run the commands below if imports fail\n",
        "# !conda install numpy pytorch torchvision cpuonly -c pytorch -y\n",
        "# !pip install matplotlib --upgrade --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UNm2R6NZeqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSfySWpaZeqd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383,
          "referenced_widgets": [
            "b12df51a0b1c4d249d8ba90f7c44a754",
            "65c906d5736d4222b0f0426159e3e959",
            "4aa369f8101643148c55d06693d16c1e",
            "eb357f5fc2b24029a7b422f54be5c6f3",
            "57795e62409d4f03a35a550080698ff6",
            "ac1f9901ff6d4e49b762b40d8a194819",
            "f12d8424845a4e428b5e248932f00aa2",
            "2b59023b08ee4b2e9d8ee1e363fe27b8",
            "c129edc1016649deb6d21c0d7dc48ea5",
            "8ec4916e32db49b593e52f457e4d0704",
            "228502e9e4fa4ae28a5e9f6919bca321",
            "bc57f0ac4bbc40ab9f3ceec5edf60d2a",
            "a6157cacc3084fd8a567a370326fbc61",
            "ecdfe475a1ae4730924be4f8e0a7cf01",
            "292ad33fd4574bb790f7c9ef6733e227",
            "9f8e73032175419784dd351ff97231c7",
            "09ff81e6939447668d5676ea6dd0df61",
            "450785243fba40beace70eb638dd8116",
            "eb7a63629bf14bfdb069ef64d4d0f7a8",
            "0569606510014b118a1ff8e26b505a33",
            "49388a787a1c47468e9c09525202f58f",
            "afa7211f74744c42ae98895065d9dab7",
            "171f23a5dfe2480fb7163412b9f36ca2",
            "26f4c6bb701d4572a3ffab7ccc04b253",
            "9ef925594bd14fbbabd6d53ab07c825e",
            "70b9b71dceb643dfa7bf74a8bcb64ad6",
            "29bc5ff73c8943a8bd546ebcaf862826",
            "b3dcea380d284d159b49ea53a170a4c8",
            "cc03b7d2d54e48b69cce60418535fa9c",
            "4be037f64a38428c8ab0421d9dcb6c55",
            "da149dc42cda428299361bbec7fcbff1",
            "e9510c7aeaaf403b950cf9ab0f6ad714"
          ]
        },
        "outputId": "cdf72e47-66ee-4157-b866-c2469dd45b94"
      },
      "source": [
        "# Download training dataset\n",
        "dataset = MNIST(root='data/', download=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b12df51a0b1c4d249d8ba90f7c44a754",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c129edc1016649deb6d21c0d7dc48ea5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09ff81e6939447668d5676ea6dd0df61",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ef925594bd14fbbabd6d53ab07c825e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-Ud9hQgZeqf",
        "colab_type": "text"
      },
      "source": [
        "When this statement is executed for the first time, it downloads the data to the `data/` directory next to the notebook and creates a PyTorch `Dataset`. On subsequent executions, the download is skipped as the data is already downloaded. Let's check the size of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SwFWmz8Zeqg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad717c11-3581-4602-84d6-f5aa2f587e61"
      },
      "source": [
        "len(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjccrxJAZeqi",
        "colab_type": "text"
      },
      "source": [
        "The dataset has 60,000 images which can be used to train the model. There is also an additonal test set of 10,000 images which can be created by passing `train=False` to the `MNIST` class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eTIcmKaZeqi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45a845d6-83a3-444c-e976-15a4eaa6ba9a"
      },
      "source": [
        "test_dataset = MNIST(root='data/', train=False)\n",
        "len(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81i6Nwa-Zeqk",
        "colab_type": "text"
      },
      "source": [
        "Let's look at a sample element from the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhoN6kYZZeql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5bd0f8d3-1da8-41bb-ab07-74c43efcda49"
      },
      "source": [
        "dataset[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PIL.Image.Image image mode=L size=28x28 at 0x7F3B3D4E88D0>, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e101G0LgZeqn",
        "colab_type": "text"
      },
      "source": [
        "It's a pair, consisting of a 28x28 image and a label. The image is an object of the class `PIL.Image.Image`, which is a part of the Python imaging library [Pillow](https://pillow.readthedocs.io/en/stable/). We can view the image within Jupyter using [`matplotlib`](https://matplotlib.org/), the de-facto plotting and graphing library for data science in Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDoBtFIlZeqn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "4fad306e-5b7c-44e6-cae6-4bd411169d06"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QayBZErZeqp",
        "colab_type": "text"
      },
      "source": [
        "Along with importing `matplotlib`, a special statement `%matplotlib inline` is added to indicate to Jupyter that we want to plot the graphs within the notebook. Without this line, Jupyter will show the image in a popup. Statements starting with `%` are called IPython magic commands, and are used to configure the behavior of Jupyter itself. You can find a full list of magic commands here: https://ipython.readthedocs.io/en/stable/interactive/magics.html .\n",
        "\n",
        "Let's look at a couple of images from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tNMOjgYZeqq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "08fa5208-bcb8-4797-a1f8-45a1a7575269"
      },
      "source": [
        "image, label = dataset[0]\n",
        "plt.imshow(image, cmap='gray')\n",
        "print('Label:', label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk9UQmnAZeqs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "53da56d0-5949-4bdb-f6eb-e8d4a4b6a644"
      },
      "source": [
        "image, label = dataset[10]\n",
        "plt.imshow(image, cmap='gray')\n",
        "print('Label:', label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2E7ruLBZeqt",
        "colab_type": "text"
      },
      "source": [
        "It's evident that these images are quite small in size, and recognizing the digits can sometimes be hard even for the human eye. While it's useful to look at these images, there's just one problem here: PyTorch doesn't know how to work with images. We need to convert the images into tensors. We can do this by specifying a transform while creating our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC8dMyKdZequ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJh9ogcVZeqw",
        "colab_type": "text"
      },
      "source": [
        "PyTorch datasets allow us to specify one or more transformation functions which are applied to the images as they are loaded. `torchvision.transforms` contains many such predefined functions, and we'll use the `ToTensor` transform to convert images into PyTorch tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PprLLexuZeqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MNIST dataset (images and labels)\n",
        "dataset = MNIST(root='data/', \n",
        "                train=True,\n",
        "                transform=transforms.ToTensor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Eys_SyJZeqy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "43bef5c4-3652-41b8-b4db-534143d95e42"
      },
      "source": [
        "img_tensor, label = dataset[0]\n",
        "print(img_tensor.shape, label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 28, 28]) 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvlKjnJgZeq0",
        "colab_type": "text"
      },
      "source": [
        "The image is now converted to a 1x28x28 tensor. The first dimension is used to keep track of the color channels. Since images in the MNIST dataset are grayscale, there's just one channel. Other datasets have images with color, in which case there are 3 channels: red, green and blue (RGB). Let's look at some sample values inside the tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nswgPxLZeq1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "2ced43f4-e787-4ad2-e999-d6136c600f69"
      },
      "source": [
        "print(img_tensor[:,10:15,10:15])\n",
        "print(torch.max(img_tensor), torch.min(img_tensor))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[0.0039, 0.6039, 0.9922, 0.3529, 0.0000],\n",
            "         [0.0000, 0.5451, 0.9922, 0.7451, 0.0078],\n",
            "         [0.0000, 0.0431, 0.7451, 0.9922, 0.2745],\n",
            "         [0.0000, 0.0000, 0.1373, 0.9451, 0.8824],\n",
            "         [0.0000, 0.0000, 0.0000, 0.3176, 0.9412]]])\n",
            "tensor(1.) tensor(0.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Gdxcby3Zeq3",
        "colab_type": "text"
      },
      "source": [
        "The values range from 0 to 1, with 0 representing black, 1 white and the values in between different shades of grey. We can also plot the tensor as an image using `plt.imshow`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG-AFx0nZeq3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "181029b8-e525-49fd-b5e6-1ca78b13e4cb"
      },
      "source": [
        "# Plot the image by passing in the 28x28 matrix\n",
        "plt.imshow(img_tensor[0,10:15,10:15], cmap='gray');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAJMElEQVR4nO3d34uUhR7H8c/nrEZRB7qwi3BFIyKQ4BSIBF4EQmQWdVtg3VR7cwKDIOqyfyC66WapSEiMoC6iOoSQEUFWW22SWWA/DhmB5yBa3RTmp4sZDh7ZdZ8Z55lnni/vFyzs7AwzH2TfPjOzy7NOIgB1/K3rAQAmi6iBYogaKIaogWKIGihmXRt3ars3b6lv3ry56wkj2bBhQ9cTRvL99993PaGxU6dOdT1hJEm80tfdxo+0bMde8fFmzuLiYtcTRvLwww93PWEke/bs6XpCY/v37+96wkhWi5qn30AxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDGNora9y/Y3to/bfrLtUQDGt2bUtuckPSfpTklbJd1ve2vbwwCMp8mReruk40m+S/KHpFck3dvuLADjahL1Rkk/nnf5xPBr/8f2gu0l20uTGgdgdBM7RXCSRUmLUr9OEQxU0+RI/ZOkTeddnh9+DcAMahL1J5JusH2d7csk3SfpjXZnARjXmk+/k5y1/aikdyTNSXoxydHWlwEYS6PX1EnelvR2y1sATAC/UQYUQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDETO/HghZJ+nHvwzJkzXU8o7ZFHHul6QmMHDhzoekJj586dW/U6jtRAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxa0Zt+0XbJ21/OY1BAC5NkyP1S5J2tbwDwISsGXWS9yWdmsIWABPAa2qgmImdTdT2gqSFSd0fgPFMLOoki5IWJcl2P84PDBTE02+gmCY/0jog6UNJN9o+Yfuh9mcBGNeaT7+T3D+NIQAmg6ffQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0U42TypxPr0znKrrzyyq4njOStt97qesJIbrvttq4nNHbHHXd0PaGxw4cP68yZM17pOo7UQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFLNm1LY32T5k+yvbR23vncYwAONZ1+A2ZyU9nuQz23+X9Kntg0m+ankbgDGseaRO8nOSz4af/yrpmKSNbQ8DMJ4mR+r/sb1F0i2SPlrhugVJCxNZBWBsjaO2fZWk1yQ9luSXC69PsihpcXjb3pwiGKim0bvfttdrEPT+JK+3OwnApWjy7rclvSDpWJJn2p8E4FI0OVLvkPSApJ22l4cfu1veBWBMa76mTvKBpBX/vAeA2cNvlAHFEDVQDFEDxRA1UAxRA8UQNVAMUQPFEDVQDFEDxRA1UAxRA8UQNVAMUQPFEDVQDFEDxRA1UIyTyZ8jkBMPtuf666/vesJIlpeXu57Q2OnTp7ue0Nju3bt15MiRFU9ewpEaKIaogWKIGiiGqIFiiBoohqiBYogaKIaogWKIGiiGqIFiiBoohqiBYogaKIaogWKIGiiGqIFiiBooZs2obV9u+2PbX9g+avvpaQwDMJ51DW7zu6SdSX6zvV7SB7b/leRwy9sAjGHNqDM4idlvw4vrhx+cgwyYUY1eU9ues70s6aSkg0k+ancWgHE1ijrJn0luljQvabvtmy68je0F20u2lyY9EkBzI737neS0pEOSdq1w3WKSbUm2TWocgNE1eff7GttXDz+/QtLtkr5uexiA8TR59/taSftsz2nwn8CrSd5sdxaAcTV59/uIpFumsAXABPAbZUAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFNPkzCeYId9++23XE0by4IMPdj2hsX379nU9obF161ZPlyM1UAxRA8UQNVAMUQPFEDVQDFEDxRA1UAxRA8UQNVAMUQPFEDVQDFEDxRA1UAxRA8UQNVAMUQPFEDVQDFEDxTSO2vac7c9tv9nmIACXZpQj9V5Jx9oaAmAyGkVte17SXZKeb3cOgEvV9Ej9rKQnJJ1b7Qa2F2wv2V6ayDIAY1kzatt3SzqZ5NOL3S7JYpJtSbZNbB2AkTU5Uu+QdI/tHyS9Immn7ZdbXQVgbGtGneSpJPNJtki6T9K7Sfa0vgzAWPg5NVDMSH92J8l7kt5rZQmAieBIDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMU4y+Tu1/yPp3xO+2w2S/jvh+2xTn/b2aavUr71tbd2c5JqVrmgl6jbYXurTmUr7tLdPW6V+7e1iK0+/gWKIGiimT1Evdj1gRH3a26etUr/2Tn1rb15TA2imT0dqAA0QNVBML6K2vcv2N7aP236y6z0XY/tF2ydtf9n1lrXY3mT7kO2vbB+1vbfrTauxfbntj21/Mdz6dNebmrA9Z/tz229O6zFnPmrbc5Kek3SnpK2S7re9tdtVF/WSpF1dj2jorKTHk2yVdKukf87wv+3vknYm+YekmyXtsn1rx5ua2Cvp2DQfcOajlrRd0vEk3yX5Q4O/vHlvx5tWleR9Sae63tFEkp+TfDb8/FcNvvk2drtqZRn4bXhx/fBjpt/ltT0v6S5Jz0/zcfsQ9UZJP553+YRm9Buvz2xvkXSLpI+6XbK64VPZZUknJR1MMrNbh56V9ISkc9N80D5EjZbZvkrSa5IeS/JL13tWk+TPJDdLmpe03fZNXW9aje27JZ1M8um0H7sPUf8kadN5l+eHX8ME2F6vQdD7k7ze9Z4mkpyWdEiz/d7FDkn32P5Bg5eMO22/PI0H7kPUn0i6wfZ1ti/T4A/fv9HxphJsW9ILko4leabrPRdj+xrbVw8/v0LS7ZK+7nbV6pI8lWQ+yRYNvmffTbJnGo8981EnOSvpUUnvaPBGzqtJjna7anW2D0j6UNKNtk/YfqjrTRexQ9IDGhxFlocfu7setYprJR2yfUSD/+gPJpnaj4n6hF8TBYqZ+SM1gNEQNVAMUQPFEDVQDFEDxRA1UAxRA8X8BY427AI3W9MfAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZVsPsWpZeq8",
        "colab_type": "text"
      },
      "source": [
        "Note that we need to pass just the 28x28 matrix to `plt.imshow`, without a channel dimension. We also pass a color map (`cmap=gray`) to indicate that we want to see a grayscale image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6H_I6Z6Zeq8",
        "colab_type": "text"
      },
      "source": [
        "## Training and Validation Datasets\n",
        "\n",
        "While building real world machine learning models, it is quite common to split the dataset into 3 parts:\n",
        "\n",
        "1. **Training set** - used to train the model i.e. compute the loss and adjust the weights of the model using gradient descent.\n",
        "2. **Validation set** - used to evaluate the model while training, adjust hyperparameters (learning rate etc.) and pick the best version of the model.\n",
        "3. **Test set** - used to compare different models, or different types of modeling approaches, and report the final accuracy of the model.\n",
        "\n",
        "In the MNIST dataset, there are 60,000 training images, and 10,000 test images. The test set is standardized so that different researchers can report the results of their models against the same set of images. \n",
        "\n",
        "Since there's no predefined validation set, we must manually split the 60,000 images into training and validation datasets. Let's set aside 10,000 randomly chosen images for validation. We can do this using the `random_spilt` method from PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXSW322YZeq9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d85c6344-89a1-4f5d-9fbd-9129df10e031"
      },
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "train_ds, val_ds = random_split(dataset, [50000, 10000])\n",
        "len(train_ds), len(val_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hz-I6jOYZeq_",
        "colab_type": "text"
      },
      "source": [
        "It's important to choose a random sample for creating a validation set, because training data is often ordered by the target labels i.e. images of 0s, followed by images of 1s, followed by images of 2s and so on. If we were to pick a 20% validation set simply by selecting the last 20% of the images, the validation set would only consist of images of 8s and 9s, whereas the training set would contain no images of 8s and 9s. This would make it impossible to train a good model using the training set, which also performs well on the validation set (and on real world data).\n",
        "\n",
        "We can now created data loaders to help us load the data in batches. We'll use a batch size of 128."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhFwhyD5Zeq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOaNZcsyZerB",
        "colab_type": "text"
      },
      "source": [
        "We set `shuffle=True` for the training dataloader, so that the batches generated in each epoch are different, and this randomization helps generalize & speed up the training process. On the other hand, since the validation dataloader is used only for evaluating the model, there is no need to shuffle the images. \n",
        "\n",
        "\n",
        "Before we move forward, let's save our progress by uploading our notebook to [Jovian.ml](https://www.jovian.ml)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDVpUostZerB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install jovian --upgrade --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_I58pxkZerC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import jovian"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAKV78z5ZerE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "58008314-0e93-45aa-f8ec-af506dc73fff"
      },
      "source": [
        "jovian.commit(project='03-logistic-regression', environment=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Please enter your API key ( from https://jovian.ml/ ):\u001b[0m\n",
            "API KEY: ··········\n",
            "API KEY: ··········\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ml/sravanchittupalli7/03-logistic-regression\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ml/sravanchittupalli7/03-logistic-regression'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-p8pnnoZerG",
        "colab_type": "text"
      },
      "source": [
        "`jovian.commit` uploads the notebook to your [Jovian.ml](https://jovian.ml) account and creates a sharable link for the notebook. You can use this link to share your work and let anyone reproduce it easily with the jovian clone command. Jovian also includes a powerful commenting interface, so you (and others) can discuss & comment on specific parts of your notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0z1RPZZZerH",
        "colab_type": "text"
      },
      "source": [
        "## Model\n",
        "\n",
        "Now that we have prepared our data loaders, we can define our model.\n",
        "\n",
        "* A **logistic regression** model is almost identical to a linear regression model i.e. there are weights and bias matrices, and the output is obtained using simple matrix operations (`pred = x @ w.t() + b`). \n",
        "\n",
        "* Just as we did with linear regression, we can use `nn.Linear` to create the model instead of defining and initializing the matrices manually.\n",
        "\n",
        "* Since `nn.Linear` expects the each training example to be a vector, each `1x28x28` image tensor needs to be flattened out into a vector of size 784 (`28*28`), before being passed into the model. \n",
        "\n",
        "* The output for each image is vector of size 10, with each element of the vector signifying the probability a particular target label (i.e. 0 to 9). The predicted label for an image is simply the one with the highest probability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6UQ0eohZerH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "input_size = 28*28\n",
        "num_classes = 10\n",
        "\n",
        "# Logistic regression model\n",
        "model = nn.Linear(input_size, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej0-ltC8ZerJ",
        "colab_type": "text"
      },
      "source": [
        "Of course, this model is a lot larger than our previous model, in terms of the number of parameters. Let's take a look at the weights and biases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPU9wsxQZerJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "16c6d0bf-a8e6-49ca-c936-643df1a2d762"
      },
      "source": [
        "print(model.weight.shape)\n",
        "model.weight"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 784])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0113, -0.0138, -0.0110,  ..., -0.0154,  0.0173,  0.0026],\n",
              "        [-0.0014,  0.0059, -0.0215,  ..., -0.0105,  0.0273, -0.0325],\n",
              "        [-0.0215,  0.0244,  0.0130,  ...,  0.0059, -0.0283,  0.0243],\n",
              "        ...,\n",
              "        [-0.0174,  0.0124, -0.0249,  ..., -0.0234, -0.0289,  0.0218],\n",
              "        [-0.0091,  0.0019,  0.0303,  ...,  0.0063,  0.0119, -0.0151],\n",
              "        [-0.0013,  0.0242, -0.0263,  ..., -0.0308, -0.0070,  0.0239]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZag05QIZerL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "8e0939ca-2aa3-4c35-d48d-4228982d08b9"
      },
      "source": [
        "print(model.bias.shape)\n",
        "model.bias"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([-2.5682e-02, -2.6690e-05, -1.9825e-02,  3.1015e-02,  4.1166e-03,\n",
              "         2.8196e-02,  2.4260e-02,  1.3504e-02,  3.4024e-02,  3.0550e-03],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3okFbH8WZerN",
        "colab_type": "text"
      },
      "source": [
        "Although there are a total of 7850 parameters here, conceptually nothing has changed so far. Let's try and generate some outputs using our model. We'll take the first batch of 100 images from our dataset, and pass them into our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-xGrPSoZerN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "outputId": "c8a40e1c-28fe-4aaa-fdbf-ae61f24afdd8"
      },
      "source": [
        "for images, labels in train_loader:\n",
        "    print(labels)\n",
        "    print(images.shape)\n",
        "    outputs = model(images)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([3, 3, 2, 8, 7, 4, 9, 2, 7, 2, 6, 7, 1, 9, 9, 7, 8, 3, 5, 8, 0, 5, 3, 5,\n",
            "        8, 9, 5, 1, 9, 8, 9, 8, 1, 9, 8, 5, 2, 9, 0, 4, 5, 5, 6, 1, 0, 5, 9, 4,\n",
            "        7, 2, 0, 6, 9, 7, 4, 3, 5, 3, 2, 1, 7, 2, 7, 1, 1, 1, 1, 6, 8, 4, 4, 9,\n",
            "        5, 8, 0, 4, 0, 1, 3, 0, 8, 1, 1, 0, 8, 0, 6, 3, 7, 2, 7, 1, 9, 5, 8, 4,\n",
            "        5, 4, 2, 6, 8, 3, 5, 4, 8, 1, 4, 8, 1, 6, 2, 1, 7, 0, 4, 9, 9, 9, 4, 0,\n",
            "        4, 4, 3, 1, 4, 4, 0, 4])\n",
            "torch.Size([128, 1, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-72eddc737460>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1674\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1676\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1677\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1678\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [3584 x 28], m2: [784 x 10] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:41"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tonbmjPFZerP",
        "colab_type": "text"
      },
      "source": [
        "This leads to an error, because our input data does not have the right shape. Our images are of the shape 1x28x28, but we need them to be vectors of size 784 i.e. we need to flatten them out. We'll use the `.reshape` method of a tensor, which will allow us to efficiently 'view' each image as a flat vector, without really chaging the underlying data.\n",
        "\n",
        "To include this additional functionality within our model, we need to define a custom model, by extending the `nn.Module` class from PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cTlmf-1ZerP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MnistModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_size, num_classes)\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        xb = xb.reshape(-1, 784)\n",
        "        out = self.linear(xb)\n",
        "        return out\n",
        "    \n",
        "model = MnistModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTj5Lv7XZerQ",
        "colab_type": "text"
      },
      "source": [
        "Inside the `__init__` constructor method, we instantiate the weights and biases using `nn.Linear`. And inside the `forward` method, which is invoked when we pass a batch of inputs to the model, we flatten out the input tensor, and then pass it into `self.linear`.\n",
        "\n",
        "`xb.reshape(-1, 28*28)` indicates to PyTorch that we want a *view* of the `xb` tensor with two dimensions, where the length along the 2nd dimension is 28\\*28 (i.e. 784). One argument to `.reshape` can be set to `-1` (in this case the first dimension), to let PyTorch figure it out automatically based on the shape of the original tensor.\n",
        "\n",
        "Note that the model no longer has `.weight` and `.bias` attributes (as they are now inside the `.linear` attribute), but it does have a `.parameters` method which returns a list containing the weights and bias, and can be used by a PyTorch optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1fg96H2ZerR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "b8668446-f3c7-4b52-c085-53494275ace6"
      },
      "source": [
        "print(model.linear.weight.shape, model.linear.bias.shape)\n",
        "list(model.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 784]) torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.0156, -0.0341, -0.0126,  ..., -0.0354, -0.0237, -0.0320],\n",
              "         [ 0.0151,  0.0140,  0.0335,  ...,  0.0173,  0.0295,  0.0318],\n",
              "         [ 0.0357,  0.0003, -0.0243,  ..., -0.0339,  0.0047,  0.0307],\n",
              "         ...,\n",
              "         [ 0.0221, -0.0347,  0.0032,  ...,  0.0295, -0.0279, -0.0353],\n",
              "         [-0.0260, -0.0101, -0.0246,  ...,  0.0224, -0.0164,  0.0105],\n",
              "         [-0.0168, -0.0217,  0.0353,  ...,  0.0296,  0.0286, -0.0073]],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([ 0.0261,  0.0046,  0.0080, -0.0245,  0.0144,  0.0164,  0.0189,  0.0143,\n",
              "          0.0254, -0.0219], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAzrq3zGZerT",
        "colab_type": "text"
      },
      "source": [
        "Our new custom model can be used in the exact same way as before. Let's see if it works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZikk71lZerT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "8c25ed85-2e05-4888-bc73-55898de13ef1"
      },
      "source": [
        "for images, labels in train_loader:\n",
        "    outputs = model(images)\n",
        "    break\n",
        "\n",
        "print('outputs.shape : ', outputs.shape)\n",
        "print('Sample outputs :\\n', outputs[:2].data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "outputs.shape :  torch.Size([128, 10])\n",
            "Sample outputs :\n",
            " tensor([[-0.0217, -0.2228,  0.0107, -0.5474, -0.2065, -0.1033, -0.1884, -0.1565,\n",
            "         -0.4080,  0.2521],\n",
            "        [ 0.0574,  0.0142, -0.2581, -0.0411,  0.1101,  0.1248,  0.1133,  0.1521,\n",
            "         -0.2533, -0.0268]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tZTd_yPZerV",
        "colab_type": "text"
      },
      "source": [
        "For each of the 100 input images, we get 10 outputs, one for each class. As discussed earlier, we'd like these outputs to represent probabilities, but for that the elements of each output row must lie between 0 to 1 and add up to 1, which is clearly not the case here. \n",
        "\n",
        "To convert the output rows into probabilities, we use the softmax function, which has the following formula:\n",
        "\n",
        "![softmax](https://i.imgur.com/EAh9jLN.png)\n",
        "\n",
        "First we replace each element `yi` in an output row by `e^yi`, which makes all the elements positive, and then we divide each element by the sum of all elements to ensure that they add up to 1. \n",
        "\n",
        "While it's easy to implement the softmax function (you should try it!), we'll use the implementation that's provided within PyTorch, because it works well with multidimensional tensors (a list of output rows in our case)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDbsICxqZerV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXOfJrk1ZerW",
        "colab_type": "text"
      },
      "source": [
        "The softmax function is included in the `torch.nn.functional` package, and requires us to specify a dimension along which the softmax must be applied."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmyhfeEQZerW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "1ee9c29c-adb8-4af8-911a-89167397faf0"
      },
      "source": [
        "# Apply softmax for each output row\n",
        "probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "# Look at sample probabilities\n",
        "print(\"Sample probabilities:\\n\", probs[:2].data)\n",
        "\n",
        "# Add up the probabilities of an output row\n",
        "print(\"Sum: \", torch.sum(probs[0]).item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample probabilities:\n",
            " tensor([[0.1122, 0.0918, 0.1159, 0.0663, 0.0933, 0.1034, 0.0950, 0.0981, 0.0763,\n",
            "         0.1476],\n",
            "        [0.1050, 0.1005, 0.0766, 0.0951, 0.1107, 0.1123, 0.1110, 0.1154, 0.0769,\n",
            "         0.0965]])\n",
            "Sum:  0.9999998807907104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YHKZ2izZerY",
        "colab_type": "text"
      },
      "source": [
        "Finally, we can determine the predicted label for each image by simply choosing the index of the element with the highest probability in each output row. This is done using `torch.max`, which returns the largest element and the index of the largest element along a particular dimension of a tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY9S8ucHZerY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "cf5b61a5-4688-43f9-cda1-93f1d31042ff"
      },
      "source": [
        "max_probs, preds = torch.max(probs, dim=1)\n",
        "print(preds)\n",
        "print(max_probs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([9, 7, 9, 6, 0, 5, 0, 9, 0, 9, 9, 0, 0, 5, 3, 5, 5, 0, 0, 5, 9, 9, 9, 0,\n",
            "        5, 9, 7, 5, 7, 5, 9, 4, 2, 4, 5, 0, 0, 6, 5, 5, 9, 9, 7, 6, 9, 9, 6, 4,\n",
            "        4, 9, 3, 9, 0, 9, 4, 5, 9, 0, 4, 0, 4, 9, 5, 0, 0, 0, 9, 7, 7, 0, 0, 9,\n",
            "        5, 0, 0, 5, 5, 5, 6, 5, 5, 9, 9, 6, 4, 9, 9, 5, 7, 7, 0, 7, 4, 7, 9, 0,\n",
            "        0, 9, 0, 5, 5, 5, 0, 7, 9, 7, 9, 5, 6, 0, 0, 5, 9, 0, 0, 5, 4, 9, 5, 0,\n",
            "        9, 7, 9, 0, 0, 9, 4, 6])\n",
            "tensor([0.1476, 0.1154, 0.1225, 0.1499, 0.1431, 0.1134, 0.1244, 0.1251, 0.1363,\n",
            "        0.1277, 0.1307, 0.1449, 0.1461, 0.1172, 0.1206, 0.1336, 0.1284, 0.1236,\n",
            "        0.1221, 0.1417, 0.1312, 0.1386, 0.1348, 0.1326, 0.1255, 0.1304, 0.1687,\n",
            "        0.1266, 0.1219, 0.1293, 0.1295, 0.1464, 0.1182, 0.1447, 0.1270, 0.1284,\n",
            "        0.1321, 0.1320, 0.1253, 0.1373, 0.1483, 0.1365, 0.1275, 0.1298, 0.1269,\n",
            "        0.1363, 0.1298, 0.1141, 0.1477, 0.1230, 0.1248, 0.1156, 0.1298, 0.1468,\n",
            "        0.1440, 0.1409, 0.1311, 0.1291, 0.1308, 0.1247, 0.1237, 0.1270, 0.1382,\n",
            "        0.1262, 0.1300, 0.1179, 0.1773, 0.1464, 0.1155, 0.1279, 0.1281, 0.1182,\n",
            "        0.1193, 0.1263, 0.1392, 0.1249, 0.1229, 0.1369, 0.1391, 0.1177, 0.1195,\n",
            "        0.1377, 0.1178, 0.1307, 0.1342, 0.1465, 0.1241, 0.1502, 0.1349, 0.1281,\n",
            "        0.1467, 0.1288, 0.1282, 0.1416, 0.1658, 0.1189, 0.1291, 0.1480, 0.1250,\n",
            "        0.1718, 0.1394, 0.1362, 0.1449, 0.1474, 0.1177, 0.1270, 0.1567, 0.1164,\n",
            "        0.1219, 0.1194, 0.1304, 0.1154, 0.1566, 0.1268, 0.1232, 0.1349, 0.1195,\n",
            "        0.1192, 0.1440, 0.1284, 0.1663, 0.1283, 0.1462, 0.1394, 0.1180, 0.1304,\n",
            "        0.1385, 0.1356], grad_fn=<MaxBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEnNXbXXZera",
        "colab_type": "text"
      },
      "source": [
        "The numbers printed above are the predicted labels for the first batch of training images. Let's compare them with the actual labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoN0SNfuZera",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "50d64bce-93e9-4b33-dc6e-191376b5c726"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([8, 8, 1, 3, 6, 4, 1, 3, 4, 9, 3, 8, 0, 4, 0, 9, 9, 4, 8, 8, 5, 6, 5, 2,\n",
              "        4, 0, 0, 2, 8, 4, 9, 7, 6, 2, 7, 8, 8, 5, 7, 7, 0, 3, 7, 3, 0, 6, 7, 7,\n",
              "        4, 4, 8, 9, 1, 8, 4, 4, 0, 7, 7, 3, 4, 2, 9, 4, 1, 1, 6, 0, 4, 6, 1, 7,\n",
              "        4, 7, 9, 8, 4, 5, 5, 1, 4, 5, 9, 6, 6, 0, 8, 5, 7, 0, 6, 4, 1, 7, 6, 1,\n",
              "        6, 6, 6, 7, 8, 9, 9, 2, 7, 7, 3, 1, 3, 1, 1, 9, 8, 1, 5, 4, 5, 3, 4, 1,\n",
              "        3, 9, 6, 1, 4, 8, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojYITZqqZerc",
        "colab_type": "text"
      },
      "source": [
        "Clearly, the predicted and the actual labels are completely different. Obviously, that's because we have started with randomly initialized weights and biases. We need to train the model i.e. adjust the weights using gradient descent to make better predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrkJmahdZerc",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation Metric and Loss Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X4AbAXmZerc",
        "colab_type": "text"
      },
      "source": [
        "Just as with linear regression, we need a way to evaluate how well our model is performing. A natural way to do this would be to find the percentage of labels that were predicted correctly i.e. the **accuracy** of the predictions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyzF_9OfZerc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro6lBw-AZere",
        "colab_type": "text"
      },
      "source": [
        "The `==` performs an element-wise comparison of two tensors with the same shape, and returns a tensor of the same shape, containing 0s for unequal elements, and 1s for equal elements. Passing the result to `torch.sum` returns the number of labels that were predicted correctly. Finally, we divide by the total number of images to get the accuracy. \n",
        "\n",
        "Note that we don't need to apply softmax to the outputs, since it doesn't change the relative order of the results. This is because `e^x` is an increasing function i.e. if `y1 > y2`, then `e^y1 > e^y2` and the same holds true after averaging out the values to get the softmax.\n",
        "\n",
        "Let's calculate the accuracy of the current model, on the first batch of data. Obviously, we expect it to be pretty bad."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1iK66vJZere",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cbc3bd6e-7c22-4781-e1b5-8b35e6dce8bb"
      },
      "source": [
        "accuracy(outputs, labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1172)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Iz8JCxxZerg",
        "colab_type": "text"
      },
      "source": [
        "While the accuracy is a great way for us (humans) to evaluate the model, it can't be used as a loss function for optimizing our model using gradient descent, for the following reasons:\n",
        "\n",
        "1. It's not a differentiable function. `torch.max` and `==` are both non-continuous and non-differentiable operations, so we can't use the accuracy for computing gradients w.r.t the weights and biases.\n",
        "\n",
        "2. It doesn't take into account the actual probabilities predicted by the model, so it can't provide sufficient feedback for incremental improvements. \n",
        "\n",
        "Due to these reasons, accuracy is a great **evaluation metric** for classification, but not a good loss function. A commonly used loss function for classification problems is the **cross entropy**, which has the following formula:\n",
        "\n",
        "![cross-entropy](https://i.imgur.com/VDRDl1D.png)\n",
        "\n",
        "While it looks complicated, it's actually quite simple:\n",
        "\n",
        "* For each output row, pick the predicted probability for the correct label. E.g. if the predicted probabilities for an image are `[0.1, 0.3, 0.2, ...]` and the correct label is `1`, we pick the corresponding element `0.3` and ignore the rest.\n",
        "\n",
        "* Then, take the [logarithm](https://en.wikipedia.org/wiki/Logarithm) of the picked probability. If the probability is high i.e. close to 1, then its logarithm is a very small negative value, close to 0. And if the probability is low (close to 0), then the logarithm is a very large negative value. We also multiply the result by -1, which results is a large postive value of the loss for poor predictions.\n",
        "\n",
        "* Finally, take the average of the cross entropy across all the output rows to get the overall loss for a batch of data.\n",
        "\n",
        "Unlike accuracy, cross-entropy is a continuous and differentiable function that also provides good feedback for incremental improvements in the model (a slightly higher probability for the correct label leads to a lower loss). This makes it a good choice for the loss function. \n",
        "\n",
        "As you might expect, PyTorch provides an efficient and tensor-friendly implementation of cross entropy as part of the `torch.nn.functional` package. Moreover, it also performs softmax internally, so we can directly pass in the outputs of the model without converting them into probabilities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y81lxBMWZerg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_fn = F.cross_entropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2be4F1zPZeri",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06cc89db-2d23-4ce4-b3d4-5d66f7ea403e"
      },
      "source": [
        "# Loss for current batch of data\n",
        "loss = loss_fn(outputs, labels)\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.3316, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4M1PGhXZerl",
        "colab_type": "text"
      },
      "source": [
        "Since the cross entropy is the negative logarithm of the predicted probability of the correct label averaged over all training samples, one way to interpret the resulting number e.g. `2.23` is look at `e^-2.23` which is around `0.1` as the predicted probability of the correct label, on average. *Lower the loss, better the model.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNW4ek83Zerl",
        "colab_type": "text"
      },
      "source": [
        "## Training the model\n",
        "\n",
        "Now that we have defined the data loaders, model, loss function and optimizer, we are ready to train the model. The training process is identical to linear regression, with the addition of a \"validation phase\" to evaluate the model in each epoch. Here's what it looks like in pseudocode:\n",
        "\n",
        "```\n",
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    for batch in train_loader:\n",
        "        # Generate predictions\n",
        "        # Calculate loss\n",
        "        # Compute gradients\n",
        "        # Update weights\n",
        "        # Reset gradients\n",
        "    \n",
        "    # Validation phase\n",
        "    for batch in val_loader:\n",
        "        # Generate predictions\n",
        "        # Calculate loss\n",
        "        # Calculate metrics (accuracy etc.)\n",
        "    # Calculate average validation loss & metrics\n",
        "    \n",
        "    # Log epoch, loss & metrics for inspection\n",
        "```\n",
        "\n",
        "Some parts of the training loop are specific the specific problem we're solving (e.g. loss function, metrics etc.) whereas others are generic and can be applied to any deep learning problem. Let's impelment the problem-specific parts within our `MnistModel` class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFxZDnROZerl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MnistModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.drop_out = nn.Dropout()\n",
        "        self.fc1 = nn.Linear(7 * 7 * 64, 1000)\n",
        "        self.fc2 = nn.Linear(1000, 10)\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.layer1(xb)\n",
        "        out = self.layer2(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.drop_out(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "    \n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss, 'val_acc': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n",
        "    \n",
        "model = MnistModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFXFIUEoZern",
        "colab_type": "text"
      },
      "source": [
        "Now we'll define an `evaluate` function, which will perform the validation phase, and a `fit` function which will peform the entire training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMiVfv__Zero",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, val_loader):\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C8DYnuaZerr",
        "colab_type": "text"
      },
      "source": [
        "The `fit` function records the validation loss and metric from each epoch and returns a history of the training process. This is useful for debuggin & visualizing the training process. Before we train the model, let's see how the model performs on the validation set with the initial set of randomly initialized weights & biases.\n",
        "\n",
        "Configurations like batch size, learning rate etc. need to picked in advance while training machine learning models, and are called hyperparameters. Picking the right hyperparameters is critical for training an accurate model within a reasonable amount of time, and is an active area of research and experimentation. Feel free to try different learning rates and see how it affects the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVE-rvw2Zers",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc080b37-1628-47d5-967f-37456f9c941d"
      },
      "source": [
        "result0 = evaluate(model, val_loader)\n",
        "result0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'val_acc': 0.09889240562915802, 'val_loss': 2.304089307785034}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrRgXGj8Zert",
        "colab_type": "text"
      },
      "source": [
        "The initial accuracy is around 10%, which is what one might expect from a randomly intialized model (since it has a 1 in 10 chance of getting a label right by guessing randomly). Also note that we are using the `.format` method with the message string to print only the first four digits after the decimal point.\n",
        "\n",
        "We are now ready to train the model. Let's train for 5 epochs and look at the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia-g3lYPZeru",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "e7b7d64d-1316-44c2-bd16-e4ef22ef3221"
      },
      "source": [
        "history1 = fit(10, 0.001, model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], val_loss: 2.2812, val_acc: 0.1860\n",
            "Epoch [1], val_loss: 2.2500, val_acc: 0.2783\n",
            "Epoch [2], val_loss: 2.1996, val_acc: 0.3894\n",
            "Epoch [3], val_loss: 2.1004, val_acc: 0.5277\n",
            "Epoch [4], val_loss: 1.8721, val_acc: 0.6395\n",
            "Epoch [5], val_loss: 1.4190, val_acc: 0.6993\n",
            "Epoch [6], val_loss: 0.9915, val_acc: 0.7454\n",
            "Epoch [7], val_loss: 0.7744, val_acc: 0.7825\n",
            "Epoch [8], val_loss: 0.6629, val_acc: 0.8026\n",
            "Epoch [9], val_loss: 0.5896, val_acc: 0.8233\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keyq2LtsZerv",
        "colab_type": "text"
      },
      "source": [
        "That's a great result! With just 5 epochs of training, our model has reached an accuracy of over 80% on the validation set. Let's see if we can improve that by training for a few more epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utnaAQ3DZerw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "92410c53-669c-4882-e1fc-0b23e267cf59"
      },
      "source": [
        "history2 = fit(5, 0.0001, model, train_loader, val_loader) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], val_loss: 0.5837, val_acc: 0.8271\n",
            "Epoch [1], val_loss: 0.5750, val_acc: 0.8301\n",
            "Epoch [2], val_loss: 0.5730, val_acc: 0.8284\n",
            "Epoch [3], val_loss: 0.5622, val_acc: 0.8313\n",
            "Epoch [4], val_loss: 0.5600, val_acc: 0.8341\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dqvNTrpZerx",
        "colab_type": "code",
        "colab": {},
        "outputId": "1aae8f80-698d-4598-ec70-2046013c28a2"
      },
      "source": [
        "history3 = fit(5, 0.001, model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], val_loss: 0.7884, val_acc: 0.8419\n",
            "Epoch [1], val_loss: 0.7604, val_acc: 0.8448\n",
            "Epoch [2], val_loss: 0.7359, val_acc: 0.8471\n",
            "Epoch [3], val_loss: 0.7144, val_acc: 0.8491\n",
            "Epoch [4], val_loss: 0.6953, val_acc: 0.8513\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ksPCorwZerz",
        "colab_type": "code",
        "colab": {},
        "outputId": "0b13fc41-f346-487f-ac52-bbcd1def5e86"
      },
      "source": [
        "history4 = fit(5, 0.001, model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], val_loss: 0.6781, val_acc: 0.8532\n",
            "Epoch [1], val_loss: 0.6627, val_acc: 0.8552\n",
            "Epoch [2], val_loss: 0.6486, val_acc: 0.8563\n",
            "Epoch [3], val_loss: 0.6359, val_acc: 0.8579\n",
            "Epoch [4], val_loss: 0.6242, val_acc: 0.8593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qteS8fWZer2",
        "colab_type": "text"
      },
      "source": [
        "While the accuracy does continue to increase as we train for more epochs, the improvements get smaller with every epoch. This is easier to see using a line graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BIdBKgJZer2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "4f241701-915d-4ac9-df77-fa4d031a7c09"
      },
      "source": [
        "# Replace these values with your results\n",
        "history = [result0] + history1 + history2 #+ history3 + history4\n",
        "accuracies = [result['val_acc'] for result in history]\n",
        "plt.plot(accuracies, '-x')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('Accuracy vs. No. of epochs');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGRywRiWZer3",
        "colab_type": "text"
      },
      "source": [
        "It's quite clear from the above picture that the model probably won't cross the accuracy threshold of 90% even after training for a very long time. One possible reason for this is that the learning rate might be too high. It's possible that the model's paramaters are \"bouncing\" around the optimal set of parameters that have the lowest loss. You can try reducing the learning rate and training for a few more epochs to see if it helps.\n",
        "\n",
        "The more likely reason that **the model just isn't powerful enough**. If you remember our initial hypothesis, we have assumed that the output (in this case the class probabilities) is a **linear function** of the input (pixel intensities), obtained by perfoming a matrix multiplication with the weights matrix and adding the bias. This is a fairly weak assumption, as there may not actually exist a linear relationship between the pixel intensities in an image and the digit it represents. While it works reasonably well for a simple dataset like MNIST (getting us to 85% accuracy), we need more sophisticated models that can capture non-linear relationships between image pixels and labels for complex tasks like recognizing everyday objects, animals etc. \n",
        "\n",
        "This would be a good time to save our work. Along with the notebook, we can also record some metrics from our training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnM_uKV7Zer3",
        "colab_type": "code",
        "colab": {},
        "outputId": "d2d7f794-64f3-41c6-a640-8ca50bb3ac11"
      },
      "source": [
        "jovian.log_metrics(val_acc=history[-1]['val_acc'], val_loss=history[-1]['val_loss'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Metrics logged.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXxNYsm1Zer5",
        "colab_type": "code",
        "colab": {},
        "outputId": "41411874-c797-4255-9306-4eeb73a1a3dd"
      },
      "source": [
        "jovian.commit(project='03-logistic-regression', environment=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[jovian] Attempting to save notebook..\u001b[0m\n",
            "[jovian] Updating notebook \"aakashns/03-logistic-regression\" on https://jovian.ml/\u001b[0m\n",
            "[jovian] Uploading notebook..\u001b[0m\n",
            "[jovian] Attaching records (metrics, hyperparameters, dataset etc.)\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ml/aakashns/03-logistic-regression\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://jovian.ml/aakashns/03-logistic-regression'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiAa4jmIZer7",
        "colab_type": "text"
      },
      "source": [
        "## Testing with individual images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6TjevCyZer7",
        "colab_type": "text"
      },
      "source": [
        "While we have been tracking the overall accuracy of a model so far, it's also a good idea to look at model's results on some sample images. Let's test out our model with some images from the predefined test dataset of 10000 images. We begin by recreating the test dataset with the `ToTensor` transform."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUcugdAyZer7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define test dataset\n",
        "test_dataset = MNIST(root='data/', \n",
        "                     train=False,\n",
        "                     transform=transforms.ToTensor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVuHqamFZer-",
        "colab_type": "text"
      },
      "source": [
        "Here's a sample image from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBCNjpwBZer-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "c4df0959-0cbc-4cc2-8e80-a1ff17a12718"
      },
      "source": [
        "img, label = test_dataset[0]\n",
        "plt.imshow(img[0], cmap='gray')\n",
        "print('Shape:', img.shape)\n",
        "print('Label:', label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape: torch.Size([1, 28, 28])\n",
            "Label: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTeOPzL4Zer_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a528dd7-7038-44ea-8896-f9235cd56463"
      },
      "source": [
        "img.unsqueeze(0).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCwbI8NAZesA",
        "colab_type": "text"
      },
      "source": [
        "Let's define a helper function `predict_image`, which returns the predicted label for a single image tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2W6G8FPZesA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_image(img, model):\n",
        "    xb = img.unsqueeze(0)\n",
        "    yb = model(xb)\n",
        "    _, preds  = torch.max(yb, dim=1)\n",
        "    return preds[0].item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCMGNNWlZesC",
        "colab_type": "text"
      },
      "source": [
        "`img.unsqueeze` simply adds another dimension at the begining of the 1x28x28 tensor, making it a 1x1x28x28 tensor, which the model views as a batch containing a single image.\n",
        "\n",
        "Let's try it out with a few images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACu8GuZmZesC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "a4471165-25cd-4112-ce9c-c934db5a0ff5"
      },
      "source": [
        "img, label = test_dataset[0]\n",
        "plt.imshow(img[0], cmap='gray')\n",
        "print('Label:', label, ', Predicted:', predict_image(img, model))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 7 , Predicted: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ce4k4M5ZesD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "fc6afbbb-2a5f-4096-fdbc-6b05d74eb21f"
      },
      "source": [
        "img, label = test_dataset[10]\n",
        "plt.imshow(img[0], cmap='gray')\n",
        "print('Label:', label, ', Predicted:', predict_image(img, model))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 0 , Predicted: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9D4s_buZesF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "4604cc18-c7e2-4e46-d2a0-c76e4688f123"
      },
      "source": [
        "img, label = test_dataset[193]\n",
        "plt.imshow(img[0], cmap='gray')\n",
        "print('Label:', label, ', Predicted:', predict_image(img, model))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 9 , Predicted: 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Gp8vzzKZesG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "61496651-c1ac-408a-9a75-c5c06a1c49a1"
      },
      "source": [
        "img, label = test_dataset[1839]\n",
        "plt.imshow(img[0], cmap='gray')\n",
        "print('Label:', label, ', Predicted:', predict_image(img, model))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 2 , Predicted: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxmYzrNSZesI",
        "colab_type": "text"
      },
      "source": [
        "Identifying where our model performs poorly can help us improve the model, by collecting more training data, increasing/decreasing the complexity of the model, and changing the hypeparameters.\n",
        "\n",
        "As a final step, let's also look at the overall loss and accuracy of the model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeAZT4hpZesI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78ab4e1b-6165-46db-adc1-695b681d3e9d"
      },
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=256)\n",
        "result = evaluate(model, test_loader)\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'val_acc': 0.8369140625, 'val_loss': 0.5551377534866333}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4fMW7UhZesJ",
        "colab_type": "text"
      },
      "source": [
        "We expect this to be similar to the accuracy/loss on the validation set. If not, we might need a better validation set that has similar data and distribution as the test set (which often comes from real world data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b9LNks6ZesK",
        "colab_type": "text"
      },
      "source": [
        "## Saving and loading the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqL84DHPZesK",
        "colab_type": "text"
      },
      "source": [
        "Since we've trained our model for a long time and achieved a resonable accuracy, it would be a good idea to save the weights and bias matrices to disk, so that we can reuse the model later and avoid retraining from scratch. Here's how you can save the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2WgpfC5ZesK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), 'MNIST_CNN.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iivQaCQdZesL",
        "colab_type": "text"
      },
      "source": [
        "The `.state_dict` method returns an `OrderedDict` containing all the weights and bias matrices mapped to the right attributes of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR0dULDgZesM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ddb70d13-2298-4012-86a8-c1b8c4b3063b"
      },
      "source": [
        "model.state_dict()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('layer1.0.weight',\n",
              "              tensor([[[[ 0.1582,  0.1817,  0.2485,  0.1977,  0.1638],\n",
              "                        [-0.1446, -0.0629,  0.0951,  0.1068, -0.1223],\n",
              "                        [ 0.0938, -0.1067, -0.1356, -0.0339,  0.0491],\n",
              "                        [-0.0739,  0.0534,  0.0821, -0.0478, -0.1298],\n",
              "                        [ 0.1498,  0.0283,  0.0963, -0.1689,  0.1211]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0778, -0.1121, -0.0811, -0.0729, -0.1704],\n",
              "                        [ 0.1326, -0.1450, -0.0462,  0.0842,  0.0616],\n",
              "                        [ 0.1194,  0.1706,  0.1468,  0.1056,  0.0129],\n",
              "                        [ 0.0528,  0.2314, -0.0521,  0.0798, -0.0580],\n",
              "                        [ 0.0711, -0.1160,  0.1443,  0.0684,  0.0249]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0150,  0.0254,  0.0546, -0.1218,  0.1505],\n",
              "                        [ 0.1972, -0.1257, -0.0596, -0.0476, -0.1299],\n",
              "                        [ 0.1987,  0.0042,  0.1638, -0.1417, -0.1038],\n",
              "                        [ 0.0665, -0.1481,  0.0799,  0.1457,  0.2268],\n",
              "                        [-0.1009, -0.1089,  0.0027,  0.0805,  0.2427]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0937,  0.0908, -0.1976, -0.0523, -0.0792],\n",
              "                        [ 0.1099, -0.1842, -0.0600, -0.1389,  0.0056],\n",
              "                        [ 0.0578,  0.1187,  0.0638,  0.1346, -0.1053],\n",
              "                        [-0.1405, -0.1875,  0.1416,  0.0443, -0.0824],\n",
              "                        [-0.1978, -0.1803,  0.0834, -0.0990, -0.0245]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.1954, -0.0859, -0.1704,  0.2048,  0.0820],\n",
              "                        [ 0.1829,  0.0837, -0.1585,  0.0739,  0.1609],\n",
              "                        [ 0.0766, -0.1888, -0.0127,  0.1231, -0.1325],\n",
              "                        [ 0.1807, -0.1869, -0.0304, -0.1742,  0.0640],\n",
              "                        [-0.1888,  0.1982, -0.0982, -0.0574, -0.1360]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.2393,  0.2381,  0.2718,  0.2351, -0.0579],\n",
              "                        [-0.0978,  0.1173,  0.0796,  0.1465, -0.0902],\n",
              "                        [ 0.0767, -0.0858,  0.1533, -0.0916,  0.2023],\n",
              "                        [ 0.0678,  0.2113,  0.2147,  0.1873, -0.1617],\n",
              "                        [-0.0964, -0.0311, -0.1387, -0.0226,  0.1985]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.1929, -0.0282, -0.1077, -0.0817, -0.0656],\n",
              "                        [ 0.0405,  0.0012,  0.0491,  0.1491, -0.0413],\n",
              "                        [ 0.0677, -0.1608,  0.0756,  0.0312,  0.2042],\n",
              "                        [-0.1685,  0.2066,  0.0773, -0.1419,  0.1316],\n",
              "                        [-0.0111,  0.0711,  0.0816, -0.1353, -0.0187]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0893, -0.0989,  0.1927,  0.1156,  0.1654],\n",
              "                        [ 0.1035,  0.0326, -0.0037,  0.0295,  0.1995],\n",
              "                        [ 0.1355, -0.1588,  0.1175,  0.0875,  0.0285],\n",
              "                        [ 0.1324,  0.0181,  0.0836, -0.0554,  0.0309],\n",
              "                        [-0.0160,  0.0911,  0.1602,  0.1740, -0.0826]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0596, -0.1261, -0.1670, -0.0775, -0.1824],\n",
              "                        [ 0.1204, -0.0504, -0.0318, -0.1229,  0.0521],\n",
              "                        [ 0.1557,  0.0185,  0.0483,  0.1001,  0.1200],\n",
              "                        [ 0.0543,  0.1263, -0.1094,  0.0954,  0.0321],\n",
              "                        [-0.0339, -0.1569, -0.1178, -0.0678, -0.0745]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.1142, -0.1044,  0.0987,  0.2180,  0.2284],\n",
              "                        [-0.0629, -0.0717,  0.0899,  0.0201,  0.2445],\n",
              "                        [ 0.1468,  0.0809,  0.1755, -0.0128, -0.1142],\n",
              "                        [ 0.0703, -0.1451,  0.0742, -0.0796,  0.1190],\n",
              "                        [-0.0428,  0.0585, -0.1568, -0.1265, -0.0155]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.1255, -0.0208,  0.1974,  0.0176, -0.1637],\n",
              "                        [-0.1526,  0.0322, -0.1608, -0.1404,  0.0990],\n",
              "                        [ 0.1188, -0.1316, -0.0748, -0.0199, -0.0487],\n",
              "                        [-0.0523, -0.0255,  0.0923, -0.0756,  0.0796],\n",
              "                        [-0.1701, -0.1901,  0.1003,  0.0359, -0.0745]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.1088,  0.1045, -0.1221,  0.0671, -0.1685],\n",
              "                        [-0.1817,  0.1500,  0.0764,  0.0758,  0.1101],\n",
              "                        [ 0.2215,  0.0463,  0.0807, -0.0936, -0.1201],\n",
              "                        [ 0.0193,  0.0375,  0.2310,  0.0350,  0.0196],\n",
              "                        [ 0.1416, -0.0636, -0.0645,  0.2035,  0.0187]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0476,  0.0299, -0.0107,  0.0915,  0.0508],\n",
              "                        [-0.1024, -0.0115, -0.0346,  0.2007,  0.0777],\n",
              "                        [ 0.1165,  0.0178, -0.1671, -0.1288, -0.0570],\n",
              "                        [-0.1700, -0.0721, -0.0019, -0.1080,  0.0786],\n",
              "                        [ 0.1675,  0.1812,  0.1257,  0.1422, -0.0837]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.2625,  0.1658,  0.2135, -0.0045,  0.1094],\n",
              "                        [ 0.0426, -0.0338,  0.1695,  0.0139, -0.0655],\n",
              "                        [-0.0793,  0.2302,  0.2595,  0.2533,  0.2075],\n",
              "                        [ 0.0853, -0.1680, -0.1168, -0.1477, -0.0185],\n",
              "                        [ 0.0553,  0.0438,  0.1956, -0.1599,  0.1537]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.1406,  0.0350, -0.1168, -0.1549,  0.0590],\n",
              "                        [ 0.1638, -0.0947, -0.0395,  0.1984, -0.1150],\n",
              "                        [-0.1462, -0.0107,  0.2039,  0.0598, -0.1679],\n",
              "                        [-0.1019,  0.0840,  0.0378, -0.1077,  0.1736],\n",
              "                        [ 0.0275, -0.0489,  0.0892, -0.0550,  0.0508]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0991, -0.1215, -0.0874, -0.0089,  0.0469],\n",
              "                        [-0.0651,  0.2059,  0.2180, -0.0634,  0.0390],\n",
              "                        [ 0.1962,  0.1628, -0.1181,  0.2174,  0.0078],\n",
              "                        [-0.1673, -0.1071,  0.0498,  0.0704,  0.2802],\n",
              "                        [ 0.1363,  0.1455,  0.2129,  0.2957,  0.2046]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0616,  0.0309,  0.0124,  0.0302,  0.0279],\n",
              "                        [-0.0736, -0.0365,  0.1201, -0.1613, -0.1217],\n",
              "                        [-0.1249, -0.1264,  0.1737,  0.1066,  0.1572],\n",
              "                        [ 0.1591, -0.0303, -0.1588,  0.1927,  0.2134],\n",
              "                        [ 0.0119,  0.0054,  0.0453,  0.0246, -0.0811]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0652,  0.0170,  0.0655,  0.2348,  0.1620],\n",
              "                        [-0.1121,  0.1614,  0.1079,  0.0297,  0.0688],\n",
              "                        [ 0.0614,  0.0003,  0.2057,  0.0501,  0.1714],\n",
              "                        [-0.1187, -0.1195, -0.1199,  0.2645,  0.0309],\n",
              "                        [-0.1380,  0.2124,  0.1912,  0.0078,  0.0530]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0130,  0.0703,  0.0341, -0.0917, -0.0501],\n",
              "                        [-0.1625,  0.2361,  0.0382, -0.0906,  0.1539],\n",
              "                        [ 0.0951,  0.0948,  0.2100,  0.1355, -0.1036],\n",
              "                        [ 0.1625,  0.2008,  0.1814, -0.0980, -0.1291],\n",
              "                        [-0.0135,  0.0960, -0.0573, -0.0324, -0.0228]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.1033, -0.0693,  0.0979,  0.1636,  0.0430],\n",
              "                        [ 0.1014,  0.0305, -0.1090,  0.0262,  0.0462],\n",
              "                        [ 0.1075, -0.0286,  0.0395, -0.1889, -0.0057],\n",
              "                        [-0.2003, -0.1988, -0.0999,  0.0797, -0.1870],\n",
              "                        [ 0.1133,  0.0602,  0.0977,  0.1538, -0.1206]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.1300,  0.0238,  0.1659, -0.0818, -0.1245],\n",
              "                        [ 0.0040,  0.1191,  0.1495, -0.0326, -0.0347],\n",
              "                        [-0.1150, -0.1052,  0.2069,  0.1064,  0.0860],\n",
              "                        [-0.1695,  0.0813, -0.0085,  0.0316, -0.0820],\n",
              "                        [ 0.1510,  0.0835, -0.0944, -0.1173,  0.0665]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.1569,  0.0658,  0.0108, -0.0304,  0.0500],\n",
              "                        [ 0.1231, -0.0566, -0.0921, -0.0421,  0.0252],\n",
              "                        [-0.1217,  0.0526,  0.2050,  0.1273, -0.1133],\n",
              "                        [ 0.0169,  0.1714,  0.1163,  0.1761, -0.1058],\n",
              "                        [-0.1049,  0.2351,  0.2244,  0.2391,  0.0715]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.1778, -0.1891,  0.0636, -0.1564, -0.0107],\n",
              "                        [-0.1808,  0.1355,  0.0413, -0.0418, -0.1642],\n",
              "                        [-0.0875,  0.1265,  0.0674,  0.0668,  0.0292],\n",
              "                        [-0.1674, -0.1871, -0.0578,  0.1180, -0.1014],\n",
              "                        [ 0.0848, -0.0631,  0.0810, -0.1430,  0.1321]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0564,  0.1049,  0.0196,  0.1684, -0.0858],\n",
              "                        [-0.0158, -0.0763,  0.1279, -0.0705, -0.0357],\n",
              "                        [-0.0477, -0.1332, -0.0235,  0.0676,  0.1923],\n",
              "                        [ 0.1691, -0.0919,  0.0459,  0.1403,  0.0950],\n",
              "                        [ 0.0450, -0.0562,  0.1002,  0.1529,  0.2321]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0852, -0.1538,  0.1316, -0.0381,  0.1245],\n",
              "                        [ 0.0158, -0.0006,  0.1673, -0.1649,  0.0747],\n",
              "                        [ 0.0289,  0.0433,  0.1137, -0.0138,  0.0647],\n",
              "                        [-0.0283, -0.1508,  0.1397, -0.1605,  0.0889],\n",
              "                        [ 0.1063, -0.1601, -0.0414,  0.0098,  0.1061]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.1368,  0.0201,  0.0620,  0.1968,  0.0087],\n",
              "                        [ 0.0918,  0.0635, -0.0022,  0.2849,  0.1032],\n",
              "                        [ 0.2173,  0.2557,  0.1776,  0.1006, -0.0474],\n",
              "                        [ 0.0842,  0.0270,  0.0148,  0.2563,  0.1716],\n",
              "                        [ 0.0384,  0.0602,  0.1601,  0.1238,  0.1069]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.1172,  0.0788, -0.0725, -0.0148,  0.1354],\n",
              "                        [-0.1969,  0.1222, -0.0860,  0.1288, -0.1701],\n",
              "                        [ 0.0173, -0.0322,  0.0853,  0.0810, -0.1512],\n",
              "                        [ 0.0121,  0.0196,  0.0432, -0.1049, -0.1587],\n",
              "                        [-0.0765, -0.1311,  0.0137, -0.1603, -0.0343]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.1729, -0.1285, -0.1614,  0.1586, -0.1372],\n",
              "                        [ 0.1996,  0.1443, -0.1366, -0.0865, -0.1636],\n",
              "                        [ 0.1163, -0.0148, -0.1205,  0.1226,  0.1778],\n",
              "                        [ 0.0373, -0.0326, -0.1219, -0.0332,  0.1002],\n",
              "                        [-0.0597, -0.1621, -0.1211, -0.1421, -0.0204]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0947,  0.0562, -0.1400,  0.1835,  0.0888],\n",
              "                        [-0.0316, -0.1920, -0.1713, -0.1263, -0.0023],\n",
              "                        [-0.0307, -0.1714,  0.1768, -0.1322, -0.0200],\n",
              "                        [-0.1268,  0.1143,  0.1571, -0.0421, -0.1584],\n",
              "                        [-0.1553, -0.0620,  0.0192, -0.0027, -0.0502]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0134,  0.1571,  0.0252,  0.1242,  0.0849],\n",
              "                        [ 0.1855,  0.0864,  0.2252,  0.3076,  0.2722],\n",
              "                        [ 0.1662,  0.0162,  0.1536,  0.0593,  0.1506],\n",
              "                        [ 0.0582,  0.0617, -0.0190,  0.2567, -0.0276],\n",
              "                        [-0.1628,  0.0655,  0.1003,  0.2039,  0.0653]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.1980,  0.1639,  0.0046, -0.0874,  0.0820],\n",
              "                        [-0.0367,  0.0568,  0.0364,  0.1998,  0.1291],\n",
              "                        [-0.1310,  0.0960, -0.0643,  0.2688,  0.2193],\n",
              "                        [ 0.1923, -0.0056,  0.0533,  0.1626, -0.0334],\n",
              "                        [ 0.0702, -0.0384, -0.0453, -0.0535,  0.0647]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0794,  0.1741,  0.1145,  0.0856,  0.0399],\n",
              "                        [-0.0578, -0.0164, -0.0555,  0.1633, -0.0214],\n",
              "                        [-0.1076,  0.0964,  0.1176,  0.1888,  0.1246],\n",
              "                        [-0.0584,  0.1002, -0.0372,  0.0838, -0.0280],\n",
              "                        [-0.0511, -0.0078,  0.2343,  0.0036,  0.0776]]]])),\n",
              "             ('layer1.0.bias',\n",
              "              tensor([ 6.0954e-02,  9.9542e-02, -3.9056e-02,  2.2978e-01, -5.5137e-02,\n",
              "                       8.4660e-08, -1.0378e-01, -1.1802e-01,  2.9846e-02,  6.2974e-02,\n",
              "                       2.0689e-01,  1.0576e-01, -3.9524e-02,  7.6338e-02,  3.6222e-03,\n",
              "                       4.2348e-02, -3.4351e-02,  1.7256e-01, -4.5686e-02, -3.5493e-02,\n",
              "                      -2.9386e-02, -3.8058e-02, -1.9032e-01,  1.5230e-01, -5.7682e-02,\n",
              "                      -1.8660e-02,  1.3779e-01, -1.5323e-01, -7.0150e-02,  1.4533e-01,\n",
              "                       1.7768e-01,  9.1796e-07])),\n",
              "             ('layer2.0.weight',\n",
              "              tensor([[[[ 1.2116e-02, -1.2315e-02, -3.2684e-02,  1.5904e-03, -1.7764e-02],\n",
              "                        [-2.7231e-02,  2.1697e-02, -2.3529e-02, -2.7247e-02,  2.0476e-03],\n",
              "                        [-4.6334e-03,  1.8052e-02, -2.1896e-02, -3.8068e-03, -3.5479e-02],\n",
              "                        [ 1.2847e-02,  1.4811e-02, -2.1527e-02,  3.1501e-02,  1.6693e-02],\n",
              "                        [-1.8018e-02, -3.4315e-02, -3.3846e-02, -9.1720e-03,  5.4849e-03]],\n",
              "              \n",
              "                       [[ 1.8743e-02,  4.4102e-04,  1.1734e-02,  2.5235e-02,  1.2177e-02],\n",
              "                        [-3.2448e-02,  2.2198e-02,  2.1231e-03,  2.0611e-02,  2.8988e-02],\n",
              "                        [-1.0958e-02,  1.2960e-02, -1.4773e-02,  1.4826e-02, -4.2191e-03],\n",
              "                        [ 1.4152e-02,  2.1816e-02, -2.1261e-02,  9.0193e-03,  1.0014e-02],\n",
              "                        [-2.1071e-02,  5.7856e-03, -1.8423e-02,  2.1954e-02,  3.1645e-02]],\n",
              "              \n",
              "                       [[-2.8296e-02,  1.6605e-02, -1.6044e-03, -7.3513e-03, -1.1168e-03],\n",
              "                        [-2.3448e-02,  1.3096e-02,  2.2928e-02,  1.1035e-02,  2.2461e-02],\n",
              "                        [-1.0266e-02,  1.2541e-02,  1.5376e-02,  3.3983e-02,  5.3127e-03],\n",
              "                        [ 3.0788e-02,  2.5781e-02, -1.6244e-02, -2.1457e-02, -2.7566e-02],\n",
              "                        [-1.3079e-02, -3.3932e-02,  1.4485e-02, -1.0853e-02, -3.0215e-02]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-1.8260e-02, -1.2899e-02, -7.6311e-03, -2.0917e-02,  2.9906e-02],\n",
              "                        [-1.1099e-02,  3.2550e-02,  2.4498e-02, -1.5851e-03,  1.5318e-02],\n",
              "                        [ 3.2511e-02, -1.0018e-02, -1.1770e-02,  3.8490e-02, -2.7503e-02],\n",
              "                        [ 2.8671e-02, -2.4932e-03,  3.5616e-02,  1.2896e-02, -1.3362e-02],\n",
              "                        [-1.4081e-02, -2.0160e-02, -2.9633e-02,  3.3380e-02, -4.7000e-03]],\n",
              "              \n",
              "                       [[ 3.3691e-03,  3.0773e-02,  2.7782e-02,  2.8356e-02,  5.4958e-03],\n",
              "                        [ 2.1271e-02,  3.6573e-02, -3.2448e-03, -4.2483e-03, -1.5632e-02],\n",
              "                        [ 2.3182e-02,  1.2405e-02, -2.6398e-02,  1.2776e-02, -1.2253e-02],\n",
              "                        [ 9.6645e-03, -9.9412e-03,  3.1786e-02, -2.8100e-02, -8.2561e-04],\n",
              "                        [ 7.9465e-03,  6.0070e-03, -8.8475e-03,  1.8711e-02, -1.3189e-02]],\n",
              "              \n",
              "                       [[ 1.3651e-02, -1.1792e-02,  3.4805e-02,  1.8667e-02,  3.0341e-02],\n",
              "                        [-3.3215e-02, -1.4070e-02,  1.3905e-02, -3.5213e-02, -6.4666e-03],\n",
              "                        [-4.9545e-03, -2.3659e-02,  1.3692e-02, -1.8306e-02,  5.8245e-03],\n",
              "                        [-1.7737e-02, -2.7317e-02,  3.3363e-02, -7.8728e-03, -4.3404e-04],\n",
              "                        [ 1.5837e-02,  2.3554e-03,  2.6705e-02,  2.7674e-02,  1.4410e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.3577e-02, -1.8838e-02, -8.0372e-03, -1.8872e-02,  4.4445e-03],\n",
              "                        [ 3.9529e-03, -2.2505e-02, -2.7981e-02,  2.3251e-02, -1.5536e-02],\n",
              "                        [-1.7346e-02,  1.3886e-02, -1.3470e-02,  1.7516e-02,  1.9436e-02],\n",
              "                        [ 2.2974e-02,  6.7244e-03, -1.5021e-02, -8.4558e-05, -3.1285e-02],\n",
              "                        [-1.6809e-02, -1.6028e-02, -1.1049e-02,  2.1336e-02, -4.4189e-04]],\n",
              "              \n",
              "                       [[-3.1169e-02, -3.3100e-02,  2.9421e-02,  4.0018e-03,  1.1322e-02],\n",
              "                        [-2.1461e-02,  2.5605e-02, -3.3016e-03, -2.3605e-02, -2.5959e-02],\n",
              "                        [ 1.9961e-02,  1.7279e-02,  2.0111e-02,  2.9163e-02, -2.5768e-02],\n",
              "                        [-3.0132e-03,  8.2646e-03, -2.6624e-02, -5.1784e-03,  1.9406e-02],\n",
              "                        [ 3.4656e-02,  2.4185e-02,  1.5749e-02,  5.4120e-03,  1.9178e-02]],\n",
              "              \n",
              "                       [[-1.0162e-02,  2.5099e-03, -9.8826e-04, -8.8558e-03,  1.4986e-02],\n",
              "                        [-2.6799e-02,  3.0234e-03, -3.0140e-02,  1.8992e-02,  1.3443e-02],\n",
              "                        [-1.2216e-02, -1.2595e-02, -8.3192e-03, -2.1808e-02, -1.5536e-02],\n",
              "                        [-7.4535e-04, -1.0513e-03,  3.2411e-02, -1.3250e-02,  2.3142e-02],\n",
              "                        [ 1.7041e-02,  5.4532e-03, -1.9034e-02, -8.7547e-03,  6.8777e-04]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-2.4641e-02,  2.8009e-02, -2.2697e-02, -1.9447e-02, -9.3452e-03],\n",
              "                        [-2.5024e-02, -1.0863e-02,  3.2460e-02, -4.0125e-03,  1.8586e-02],\n",
              "                        [-3.0729e-02,  1.7685e-02, -9.7966e-03,  3.2642e-02,  2.1943e-02],\n",
              "                        [ 1.2862e-02, -2.4255e-02, -2.9720e-02,  3.7637e-02,  3.5818e-02],\n",
              "                        [ 3.5140e-02, -2.7983e-02, -1.2047e-03, -4.7735e-03,  2.8188e-02]],\n",
              "              \n",
              "                       [[ 2.5159e-02, -1.8555e-02,  3.2467e-02,  2.2559e-02,  1.4933e-02],\n",
              "                        [-1.4872e-02,  2.3414e-02,  9.1252e-03, -4.6136e-03, -1.3216e-02],\n",
              "                        [-1.5749e-02,  1.1824e-02,  2.9191e-02, -1.1376e-02, -2.7001e-02],\n",
              "                        [ 1.1901e-02,  3.9927e-03,  6.9206e-03,  1.2288e-02,  2.1866e-02],\n",
              "                        [-2.6401e-02, -3.3711e-02,  1.2135e-02,  9.2592e-03, -1.2448e-02]],\n",
              "              \n",
              "                       [[-1.3373e-02,  5.7074e-04,  2.7289e-02, -2.4249e-02, -3.0801e-02],\n",
              "                        [ 1.2344e-02, -1.2697e-02, -3.5727e-02,  1.3062e-02, -1.5876e-03],\n",
              "                        [-6.2104e-03, -3.4569e-02, -2.3821e-02,  3.1415e-02, -1.1806e-02],\n",
              "                        [ 3.1544e-02,  2.9021e-02,  2.9669e-02, -3.0437e-02,  3.7895e-02],\n",
              "                        [-1.9864e-02,  2.1304e-03,  2.2251e-02, -2.5772e-02,  1.7276e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-3.7239e-02,  1.8826e-02, -2.4466e-02,  2.2492e-02,  1.9890e-02],\n",
              "                        [-1.3924e-02,  1.9499e-02,  9.3452e-03, -9.4812e-04,  4.9952e-04],\n",
              "                        [ 2.0865e-02,  3.5503e-02, -3.0665e-02,  2.1839e-02,  1.2991e-02],\n",
              "                        [-8.5577e-03,  1.6581e-02,  3.3732e-02,  1.2098e-02, -4.1251e-03],\n",
              "                        [ 1.0902e-02,  2.2651e-02, -2.8829e-03,  3.2930e-02,  1.4840e-02]],\n",
              "              \n",
              "                       [[ 3.1713e-02, -5.2923e-03,  2.5093e-02,  1.8252e-02,  3.0391e-02],\n",
              "                        [ 3.4022e-02, -8.0720e-03,  1.7397e-02,  3.0563e-02,  2.9982e-02],\n",
              "                        [ 2.4500e-02, -8.9527e-03, -9.6153e-03,  7.2050e-03, -2.3782e-02],\n",
              "                        [ 2.2360e-02, -1.8548e-02, -2.8055e-02,  2.6217e-03, -1.0051e-02],\n",
              "                        [ 2.1155e-03,  2.6405e-02,  1.8215e-02,  2.5045e-02, -2.3350e-02]],\n",
              "              \n",
              "                       [[-1.1008e-02, -2.1915e-02, -2.0120e-02,  3.6647e-02,  3.2244e-02],\n",
              "                        [ 4.1475e-03,  1.1495e-02, -8.8729e-03, -2.6112e-02,  5.6954e-03],\n",
              "                        [-1.6375e-02,  2.1090e-02, -2.1022e-02,  3.5158e-02, -2.1982e-02],\n",
              "                        [ 1.6755e-03,  9.6990e-03,  2.5788e-02, -3.1484e-02,  9.0420e-03],\n",
              "                        [-5.4735e-04, -3.2301e-02,  2.6027e-02, -4.0515e-03, -3.4593e-02]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 2.4974e-02,  2.3150e-02, -2.3830e-02, -1.5720e-02, -4.0028e-02],\n",
              "                        [ 1.7599e-02,  7.4776e-04,  4.1088e-02, -9.5516e-03,  4.3058e-03],\n",
              "                        [ 4.7503e-02,  2.5299e-02, -1.1919e-02, -1.7484e-02, -4.6779e-03],\n",
              "                        [-1.4052e-02, -2.5201e-02,  1.0063e-02,  3.9930e-03, -2.4488e-02],\n",
              "                        [-3.1697e-02, -1.8679e-02, -9.2004e-03, -3.6325e-03,  1.3739e-02]],\n",
              "              \n",
              "                       [[ 1.6351e-02, -1.8237e-02,  3.4748e-02, -2.1340e-02, -1.7171e-02],\n",
              "                        [ 5.9777e-03,  1.1919e-02,  1.2967e-02,  2.6560e-02,  8.0953e-03],\n",
              "                        [ 4.2139e-02,  3.7453e-03, -7.4147e-03, -1.0947e-02,  1.8632e-02],\n",
              "                        [-8.5866e-03, -3.5916e-03, -9.8554e-03,  3.3677e-02,  3.3210e-02],\n",
              "                        [-3.9535e-03, -3.4738e-02, -2.8444e-02,  9.7621e-03, -8.0851e-03]],\n",
              "              \n",
              "                       [[-7.5107e-03,  2.2263e-02,  2.5632e-02, -1.2432e-02, -1.4278e-02],\n",
              "                        [-1.6293e-02,  3.1478e-04,  4.9462e-03, -3.6323e-02,  7.1670e-03],\n",
              "                        [ 3.6425e-02,  8.5478e-03,  1.9052e-02,  3.3618e-02,  1.5255e-02],\n",
              "                        [ 1.5005e-02, -2.3743e-02,  1.7116e-02, -1.9598e-02, -1.6082e-02],\n",
              "                        [-3.0642e-02, -3.0603e-02,  1.9107e-02, -6.6080e-03, -2.6443e-03]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[-1.0281e-02, -6.9847e-03,  2.4980e-02, -2.4227e-02, -1.9852e-03],\n",
              "                        [ 1.4234e-02,  3.2706e-02,  1.6671e-02,  3.3246e-03, -5.7340e-03],\n",
              "                        [-2.8403e-02,  1.6437e-02,  3.6523e-02, -2.0681e-02, -8.0400e-03],\n",
              "                        [-9.9345e-03,  1.8175e-04, -8.7671e-04,  1.6615e-02, -3.3058e-03],\n",
              "                        [ 1.9660e-03,  6.1425e-03, -5.2168e-03,  2.8746e-02,  1.5751e-02]],\n",
              "              \n",
              "                       [[ 6.1373e-03, -6.7786e-03,  4.2112e-02,  3.2709e-02,  3.8997e-03],\n",
              "                        [-1.7425e-02, -7.1552e-03, -1.6914e-02,  3.1663e-02,  3.1455e-02],\n",
              "                        [ 1.7735e-02, -2.3596e-02,  6.2922e-03, -4.6338e-03,  2.8728e-02],\n",
              "                        [-3.7929e-03, -3.5455e-02, -1.9576e-02,  4.0229e-04,  2.7617e-02],\n",
              "                        [ 1.5637e-02,  2.2865e-02,  1.2157e-02, -3.3014e-02,  3.4393e-02]],\n",
              "              \n",
              "                       [[-8.5673e-03, -1.6533e-02, -2.3086e-02,  7.4589e-03, -2.1698e-02],\n",
              "                        [ 6.3095e-03, -1.2160e-02, -7.1383e-03,  7.2350e-03, -1.1366e-02],\n",
              "                        [-1.1897e-02, -8.9462e-03, -3.3746e-02,  1.6040e-02, -1.8759e-02],\n",
              "                        [ 2.4428e-02,  1.6309e-02,  1.5684e-02, -2.1677e-02, -4.9574e-03],\n",
              "                        [ 3.2135e-02, -2.8177e-02, -1.0499e-02,  5.9477e-03,  9.1314e-03]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 3.2886e-02,  3.7049e-02,  2.2525e-02, -3.2302e-03, -7.2311e-03],\n",
              "                        [ 2.4845e-02,  4.7651e-02, -1.1903e-02, -1.1858e-02, -2.1514e-02],\n",
              "                        [ 1.4943e-02, -1.4243e-02, -2.3039e-02, -2.3731e-02,  3.0540e-02],\n",
              "                        [ 2.0612e-02,  1.5313e-02, -2.1185e-02, -3.5175e-02,  2.5154e-02],\n",
              "                        [-2.6221e-02, -1.4570e-02,  1.9113e-04, -1.1150e-02, -7.8050e-03]],\n",
              "              \n",
              "                       [[ 3.1247e-02,  3.9864e-02,  1.7464e-04,  1.6916e-02,  1.0650e-02],\n",
              "                        [ 4.7468e-04,  4.0833e-02,  2.3061e-02,  6.3376e-03, -2.5102e-02],\n",
              "                        [-3.0493e-02, -2.3529e-02, -2.6160e-02, -4.7894e-04, -6.6523e-03],\n",
              "                        [-1.5436e-02,  2.8400e-02, -3.1268e-02, -2.2350e-02, -1.7968e-02],\n",
              "                        [-3.3211e-02,  1.1022e-02,  1.1127e-02,  2.4085e-02, -1.9907e-02]],\n",
              "              \n",
              "                       [[ 1.9863e-02,  3.9412e-02,  3.7098e-03, -1.0549e-02, -2.9372e-02],\n",
              "                        [ 2.8145e-02, -8.4056e-03,  3.2406e-02,  3.5558e-02, -2.6443e-02],\n",
              "                        [-3.2378e-02, -1.9380e-02,  4.3074e-03,  1.7587e-02,  4.8569e-03],\n",
              "                        [-3.1020e-02,  2.8629e-02,  1.3229e-02,  1.4357e-03, -2.8421e-03],\n",
              "                        [-8.8802e-03, -2.3480e-02, -4.6418e-03,  4.0801e-03,  7.7933e-03]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 3.1073e-03,  1.4098e-02, -7.3902e-03, -7.7935e-04,  2.3332e-03],\n",
              "                        [ 1.8113e-02,  2.7960e-03,  2.1423e-02,  2.4904e-02, -3.6812e-02],\n",
              "                        [ 3.2552e-02, -1.6771e-02,  2.8876e-02,  1.3022e-02,  2.1040e-02],\n",
              "                        [ 3.2673e-02, -5.9697e-03, -2.6638e-02,  2.6728e-02,  1.8889e-03],\n",
              "                        [-6.1862e-04,  4.1947e-02,  2.2590e-02,  2.4388e-02,  1.1230e-02]],\n",
              "              \n",
              "                       [[-3.6642e-02, -2.5395e-02,  1.8881e-02,  2.2646e-02,  6.3579e-04],\n",
              "                        [-2.0989e-02,  5.4422e-03,  2.7084e-03, -3.3171e-02, -1.8261e-02],\n",
              "                        [-1.5209e-02,  4.4444e-02,  6.7310e-05, -3.0088e-03,  3.1932e-02],\n",
              "                        [ 1.1128e-02,  2.4795e-02, -7.8969e-03,  2.3738e-02, -6.7146e-03],\n",
              "                        [ 1.6636e-02, -3.5050e-02,  1.4111e-02,  4.1187e-02,  1.9668e-02]],\n",
              "              \n",
              "                       [[ 3.4997e-02, -2.8179e-02, -1.4136e-02,  1.5994e-02,  1.4932e-02],\n",
              "                        [ 1.4868e-02,  3.1366e-02,  2.5095e-02, -1.8756e-02, -3.4955e-02],\n",
              "                        [ 7.1121e-03, -1.2666e-02,  1.2600e-02,  5.3196e-03, -3.1109e-02],\n",
              "                        [-4.9112e-03, -5.7887e-03,  2.4933e-02, -8.1902e-03,  2.2319e-02],\n",
              "                        [-2.9834e-02,  2.8148e-02,  3.5912e-02, -2.6883e-02,  4.2248e-03]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-1.0939e-02,  2.0180e-02, -2.3838e-02, -2.8898e-02, -1.2752e-02],\n",
              "                        [-1.6438e-02,  4.7497e-02, -3.9338e-03, -3.4222e-02, -1.0658e-03],\n",
              "                        [ 4.6933e-02,  1.8708e-02, -1.3240e-02, -1.5668e-02, -4.6004e-02],\n",
              "                        [ 1.8891e-02,  6.0876e-02,  3.6030e-03,  4.3848e-02,  2.3894e-02],\n",
              "                        [ 2.0807e-02,  2.4557e-03, -2.6497e-03,  3.2283e-02,  4.2232e-03]],\n",
              "              \n",
              "                       [[ 1.0426e-02, -4.2911e-03, -3.5585e-03, -3.7935e-03, -9.7826e-03],\n",
              "                        [-4.5344e-03, -1.2213e-02,  1.4781e-03, -9.3208e-03, -4.4291e-02],\n",
              "                        [ 2.5721e-02, -1.3042e-03, -2.5455e-02, -6.2447e-03, -1.4290e-02],\n",
              "                        [ 1.8960e-02,  5.3636e-02,  5.7540e-03,  3.7322e-02,  5.5922e-03],\n",
              "                        [ 3.8557e-02,  1.7189e-02,  2.7594e-02,  2.3929e-02, -2.4807e-02]],\n",
              "              \n",
              "                       [[-7.8508e-03,  1.2379e-02, -8.4834e-03, -3.0231e-02, -4.4582e-02],\n",
              "                        [ 2.4128e-02,  3.3105e-02,  5.1635e-03, -3.3951e-02,  9.8105e-03],\n",
              "                        [ 1.8783e-02,  3.4619e-03, -1.2714e-02, -3.8834e-02,  1.5486e-02],\n",
              "                        [-1.2956e-02,  4.2108e-02,  3.4841e-02,  1.3325e-02,  8.2677e-04],\n",
              "                        [ 2.0912e-02,  2.6637e-02,  1.9118e-02, -2.3631e-02,  4.7566e-03]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 2.1158e-02, -1.8442e-02,  3.1529e-02, -2.8631e-03, -3.5730e-02],\n",
              "                        [ 8.0508e-03,  3.2953e-02, -6.4887e-04,  1.6324e-02, -2.1753e-02],\n",
              "                        [-2.5470e-02,  7.8729e-03, -2.0850e-02, -1.4859e-02, -9.8555e-03],\n",
              "                        [-2.6959e-02,  1.8213e-03,  9.4414e-03, -1.5917e-02,  3.6168e-02],\n",
              "                        [-2.7484e-02, -8.7121e-03, -1.0078e-02,  3.2522e-02,  2.9222e-02]],\n",
              "              \n",
              "                       [[ 2.6130e-02,  1.6826e-02,  2.7769e-02,  2.8558e-02, -2.4223e-02],\n",
              "                        [ 2.7844e-02, -1.7892e-02, -7.9504e-03,  3.1445e-02,  2.1568e-02],\n",
              "                        [-2.0683e-02, -2.2426e-02, -2.2104e-02,  1.4913e-02,  1.4331e-02],\n",
              "                        [ 2.1109e-02,  1.1915e-02, -1.9614e-02,  1.8189e-02,  2.2925e-02],\n",
              "                        [ 1.1620e-02, -2.6749e-02,  9.1467e-03, -3.4285e-02,  2.8115e-02]],\n",
              "              \n",
              "                       [[-3.5527e-02, -3.3837e-02,  3.1840e-02, -8.4875e-03,  1.9204e-02],\n",
              "                        [-1.5821e-02,  2.4743e-02, -9.5076e-03,  1.8678e-02,  2.1637e-02],\n",
              "                        [ 3.1760e-02, -1.6761e-02,  3.0161e-03, -1.3856e-02, -3.8712e-03],\n",
              "                        [ 1.4144e-02, -2.8452e-02,  2.1724e-02, -4.8074e-03,  2.9476e-02],\n",
              "                        [ 2.0348e-02, -9.5768e-03,  3.2151e-02,  2.7444e-02, -5.7356e-03]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-1.6148e-02, -2.1931e-02, -1.9009e-02, -8.4020e-03, -1.3537e-02],\n",
              "                        [-6.2439e-03,  1.3370e-02,  4.1210e-03,  1.4644e-02,  1.0199e-02],\n",
              "                        [-1.2333e-02, -2.9736e-02,  1.5892e-03, -2.5849e-02,  4.7580e-02],\n",
              "                        [ 5.8322e-03, -2.8787e-02, -3.2933e-02,  3.0988e-02,  2.8620e-02],\n",
              "                        [ 5.5575e-03, -1.7069e-02, -8.7005e-03,  1.2587e-03,  5.3828e-02]],\n",
              "              \n",
              "                       [[ 1.3677e-02, -3.1655e-02,  3.1703e-02, -1.1973e-02,  2.1160e-02],\n",
              "                        [-1.1778e-03, -2.8371e-02, -2.4004e-02, -1.1466e-02,  3.3204e-02],\n",
              "                        [ 3.3671e-02,  1.7557e-02, -9.6505e-03,  1.9733e-02,  1.6347e-02],\n",
              "                        [ 2.9782e-02,  3.5692e-03, -3.1058e-02, -4.1081e-03,  4.3268e-03],\n",
              "                        [-2.8593e-02, -1.3131e-02, -1.2144e-02, -3.5289e-03,  9.4806e-03]],\n",
              "              \n",
              "                       [[-1.9177e-02, -1.7437e-02,  2.6773e-03,  1.3022e-02,  8.7624e-03],\n",
              "                        [ 1.4331e-02, -4.1732e-03,  2.1532e-02, -1.9134e-02,  2.8771e-02],\n",
              "                        [-4.9387e-03, -1.5325e-02, -1.1807e-02,  8.4782e-03, -1.3191e-03],\n",
              "                        [ 2.9464e-02, -1.2202e-02, -2.8270e-02,  9.2605e-03,  4.7767e-02],\n",
              "                        [-2.7379e-02,  1.3945e-02, -1.0566e-02,  1.5427e-03,  3.6588e-02]]]])),\n",
              "             ('layer2.0.bias',\n",
              "              tensor([ 0.0158,  0.0267, -0.0277,  0.0117,  0.0187,  0.0172,  0.0043,  0.0390,\n",
              "                       0.0020, -0.0078, -0.0338, -0.0234,  0.0338, -0.0099, -0.0051,  0.0404,\n",
              "                      -0.0049, -0.0021, -0.0372,  0.0333,  0.0354,  0.0400, -0.0252,  0.0083,\n",
              "                       0.0223, -0.0083,  0.0099,  0.0130, -0.0302, -0.0348, -0.0156,  0.0160,\n",
              "                       0.0200, -0.0261,  0.0178, -0.0279,  0.0098,  0.0075,  0.0061,  0.0066,\n",
              "                       0.0226,  0.0062, -0.0119, -0.0306, -0.0126, -0.0219, -0.0079, -0.0318,\n",
              "                       0.0217,  0.0039, -0.0201, -0.0135, -0.0203, -0.0168,  0.0004,  0.0320,\n",
              "                      -0.0452, -0.0050, -0.0231, -0.0005,  0.0012,  0.0169, -0.0185,  0.0215])),\n",
              "             ('fc1.weight',\n",
              "              tensor([[ 0.0137, -0.0012,  0.0008,  ..., -0.0173, -0.0070, -0.0042],\n",
              "                      [ 0.0155,  0.0021,  0.0131,  ..., -0.0143,  0.0127,  0.0040],\n",
              "                      [ 0.0106, -0.0023, -0.0028,  ...,  0.0129,  0.0062,  0.0148],\n",
              "                      ...,\n",
              "                      [ 0.0152,  0.0137, -0.0082,  ..., -0.0170,  0.0007, -0.0122],\n",
              "                      [ 0.0107,  0.0060, -0.0025,  ...,  0.0049,  0.0010,  0.0107],\n",
              "                      [ 0.0135, -0.0158,  0.0178,  ..., -0.0037,  0.0161,  0.0132]])),\n",
              "             ('fc1.bias',\n",
              "              tensor([ 1.1294e-02,  1.9177e-02, -1.4297e-02,  9.6231e-03, -1.2996e-02,\n",
              "                      -1.2314e-02,  1.1591e-02,  1.6283e-02, -1.7254e-03, -1.0617e-02,\n",
              "                       1.4635e-02,  1.6584e-02,  1.6731e-02,  4.1569e-03, -1.6262e-03,\n",
              "                       1.1702e-02, -8.1786e-03,  9.1984e-03,  1.6350e-02, -3.1077e-03,\n",
              "                      -1.6214e-02,  1.0709e-03, -1.6617e-02, -1.2563e-02,  1.5140e-02,\n",
              "                       1.2578e-02, -6.2269e-03,  9.6281e-03, -1.4770e-02,  3.7778e-03,\n",
              "                       1.7549e-02,  1.2680e-02,  2.3776e-04,  1.0360e-02, -2.6128e-03,\n",
              "                       1.3162e-03, -1.6886e-02, -6.6314e-03, -1.5630e-02, -1.9636e-02,\n",
              "                       1.6522e-02, -8.0257e-03,  3.5387e-03, -3.6007e-03,  1.5182e-02,\n",
              "                      -9.2986e-03,  9.0875e-03, -7.3835e-03, -1.6188e-03,  2.4588e-03,\n",
              "                      -1.5923e-02,  9.5432e-03,  1.2450e-02, -1.5364e-02,  1.1255e-02,\n",
              "                       1.1733e-02, -1.3614e-03,  8.0913e-03, -1.4705e-02, -6.4716e-03,\n",
              "                       9.3675e-03,  6.7272e-03,  3.1809e-03, -2.6353e-03,  8.3630e-03,\n",
              "                       5.6995e-03,  9.7092e-03,  4.3413e-03, -6.3666e-03,  6.6705e-04,\n",
              "                      -1.2906e-02,  1.0030e-02,  5.0702e-04,  4.9158e-03,  8.3925e-03,\n",
              "                       1.7029e-02, -1.5674e-02,  4.8867e-03,  2.0282e-03,  1.8595e-02,\n",
              "                      -1.0155e-02, -2.0187e-03, -1.3950e-02, -1.3288e-04, -1.2469e-02,\n",
              "                      -1.2007e-02, -4.7307e-03, -1.5239e-02, -1.1732e-02,  8.0297e-03,\n",
              "                      -3.1909e-03,  1.3063e-02,  7.4727e-03,  5.5595e-03, -3.8839e-04,\n",
              "                      -4.4125e-06, -1.0888e-02,  7.8991e-03,  6.5024e-03, -1.3676e-03,\n",
              "                       1.6862e-02,  6.2256e-03,  1.9388e-02,  1.1827e-03, -1.3876e-02,\n",
              "                      -6.6061e-03, -1.1342e-02,  1.3242e-02, -7.9810e-03,  5.5287e-03,\n",
              "                       1.8453e-02,  1.0295e-02,  1.1208e-02,  1.0621e-02, -7.1689e-03,\n",
              "                       5.3324e-03,  4.3756e-03,  8.5268e-03, -9.1688e-03, -9.1026e-03,\n",
              "                       1.6504e-02, -5.6645e-03,  1.6204e-02,  2.5058e-03,  8.5047e-03,\n",
              "                      -6.8769e-03,  3.7670e-03,  3.4393e-03,  1.4682e-02, -1.5316e-02,\n",
              "                      -1.6426e-02, -2.8412e-03, -4.5599e-03, -9.4974e-03,  1.5133e-02,\n",
              "                       1.5613e-02,  1.4021e-02,  1.4486e-02, -9.5981e-03,  1.6182e-02,\n",
              "                      -1.5450e-02, -1.7905e-02, -6.6357e-03, -1.2861e-03, -1.7612e-02,\n",
              "                       7.6431e-03,  1.7522e-02, -1.4307e-02, -2.7714e-03,  3.9562e-03,\n",
              "                       1.0488e-02, -1.5529e-02,  1.0683e-02, -1.0043e-02, -7.3257e-03,\n",
              "                      -1.5288e-03, -6.7139e-03, -3.2427e-03,  1.9884e-02,  1.2131e-02,\n",
              "                      -1.5045e-03,  9.8377e-03, -4.6316e-03,  1.8626e-02, -3.8737e-03,\n",
              "                      -1.5987e-02,  1.3066e-02, -8.1729e-03,  8.6017e-03, -8.8657e-03,\n",
              "                       6.2206e-03,  1.0388e-03, -1.7398e-02, -1.1952e-02, -8.5372e-03,\n",
              "                      -8.2204e-03,  4.2722e-03,  2.9020e-03,  1.5507e-03,  1.2474e-02,\n",
              "                       1.5231e-02, -8.2181e-03,  1.8940e-02,  7.2853e-03,  1.0726e-02,\n",
              "                       1.4031e-02, -1.6647e-02, -1.8356e-03, -3.1483e-03,  1.3416e-02,\n",
              "                       1.5139e-02, -1.2259e-02,  6.8634e-03,  1.5208e-02,  2.4037e-03,\n",
              "                       1.5640e-02,  1.2585e-02, -1.0479e-02,  1.5004e-02, -1.8671e-04,\n",
              "                      -1.5483e-02,  1.2025e-02, -8.5851e-04,  8.2999e-03,  8.6514e-03,\n",
              "                      -1.4381e-02, -1.2913e-02, -8.5644e-03,  3.0219e-03, -1.4189e-02,\n",
              "                      -1.4184e-02,  4.5106e-05,  1.2479e-02,  1.2826e-02, -8.6670e-03,\n",
              "                      -8.7612e-03,  9.8932e-03,  1.4168e-02,  3.4030e-03,  3.3565e-03,\n",
              "                      -1.3965e-02, -2.4072e-03,  3.8668e-03, -7.7699e-03,  7.6877e-03,\n",
              "                       7.1625e-03,  8.2628e-03,  8.7275e-03,  1.3411e-02,  1.6605e-02,\n",
              "                      -1.7879e-02, -1.8661e-02,  2.0121e-03,  4.1694e-03, -1.6473e-02,\n",
              "                      -1.6425e-02, -2.8931e-03,  5.8782e-03, -1.4512e-02, -6.0262e-03,\n",
              "                       7.8156e-03,  5.6327e-03, -1.0583e-02, -9.8520e-03,  7.8543e-03,\n",
              "                      -1.6170e-02, -1.5945e-02,  4.6352e-03,  1.0791e-02, -1.4170e-02,\n",
              "                      -1.7575e-02,  7.3255e-03, -3.4383e-04,  1.0229e-02,  3.4895e-03,\n",
              "                      -1.1635e-02, -7.9893e-04,  1.2575e-02,  6.2744e-04,  1.3201e-02,\n",
              "                       1.2801e-02,  8.7706e-03,  9.4060e-03, -2.8249e-03,  6.1615e-03,\n",
              "                      -3.2433e-03,  4.2855e-03,  5.7234e-03, -1.0970e-02, -2.9787e-03,\n",
              "                      -7.8453e-03, -3.6837e-03,  5.1307e-03, -3.3050e-03, -8.2678e-03,\n",
              "                       3.8736e-03,  1.3737e-02, -1.3978e-02,  1.0560e-02,  4.7071e-03,\n",
              "                       6.3956e-03, -1.4334e-02, -9.0929e-03,  9.8471e-03,  1.1094e-02,\n",
              "                       1.1532e-02,  1.4619e-02,  1.3420e-03, -3.2537e-03,  9.0443e-03,\n",
              "                       4.0787e-04,  5.8272e-04, -9.6230e-03,  6.0232e-03,  1.0089e-02,\n",
              "                      -9.9479e-03, -6.2176e-03,  6.5924e-03,  1.3521e-02, -1.8266e-03,\n",
              "                      -9.1068e-03,  1.3759e-02,  2.4540e-03,  1.5147e-03, -1.0533e-02,\n",
              "                      -1.0125e-02,  4.2628e-03,  3.6151e-03,  1.8507e-02,  1.1517e-02,\n",
              "                       4.2250e-03, -2.4203e-03, -1.1256e-02, -4.2309e-03, -1.2403e-02,\n",
              "                       1.4138e-02, -1.9092e-02, -1.1986e-02,  4.1499e-03,  2.5375e-03,\n",
              "                      -7.7798e-03,  1.1412e-02, -1.2826e-02,  1.5437e-02,  1.5350e-02,\n",
              "                       1.7501e-02,  1.7519e-02,  8.6768e-03, -6.1712e-03, -1.5503e-03,\n",
              "                       1.3023e-02,  1.2911e-03, -9.0701e-03,  1.1382e-02, -1.1049e-02,\n",
              "                      -1.7213e-03,  1.2804e-02, -1.4385e-02, -1.3425e-02,  1.3913e-02,\n",
              "                      -2.9641e-03,  1.7623e-02, -1.7605e-02, -1.1764e-02,  9.5081e-03,\n",
              "                       4.4824e-03, -1.1644e-02, -1.0778e-02, -1.9400e-02, -7.4998e-03,\n",
              "                      -9.9394e-03, -7.9212e-03,  7.8225e-03, -1.3554e-03,  6.0338e-03,\n",
              "                      -1.4970e-02, -4.7086e-03,  8.8282e-03,  1.8682e-02,  6.9615e-03,\n",
              "                      -1.6041e-02, -3.9285e-04,  1.5139e-02, -7.4952e-03,  1.3257e-02,\n",
              "                      -9.7749e-03,  2.8764e-03, -9.4646e-03, -5.8139e-03, -2.6689e-03,\n",
              "                      -1.1401e-03,  1.5918e-02, -1.4782e-02,  1.5396e-02,  1.4135e-02,\n",
              "                      -2.0843e-03,  2.0485e-02, -1.2771e-02, -1.0607e-02, -8.1865e-03,\n",
              "                      -1.6075e-02,  1.4238e-02, -1.4736e-02,  8.1307e-05, -9.3420e-03,\n",
              "                       1.2730e-02, -1.1800e-02, -1.0317e-02, -7.6482e-03,  1.3534e-02,\n",
              "                       5.5962e-04,  5.6871e-03,  1.7738e-02, -1.6969e-02,  1.0025e-02,\n",
              "                       1.7435e-03, -1.2020e-02, -1.1192e-02, -1.1420e-02,  1.4631e-02,\n",
              "                      -1.6264e-02, -5.3143e-03, -1.1768e-02,  9.3138e-03, -8.8864e-03,\n",
              "                      -4.7660e-04, -4.8756e-03,  5.2845e-03,  1.2146e-02,  5.9426e-03,\n",
              "                       6.4294e-03, -1.0085e-02, -1.0546e-02,  5.6212e-03, -1.2773e-02,\n",
              "                      -3.7487e-03, -1.1028e-03,  1.6455e-02,  1.0039e-02, -1.9599e-03,\n",
              "                       1.3652e-02, -1.7956e-02,  1.3879e-02,  7.5291e-03, -8.6510e-03,\n",
              "                      -1.3307e-02,  5.8023e-03,  2.9031e-03,  3.4770e-03,  6.9776e-03,\n",
              "                      -3.8735e-04, -2.8122e-03, -2.8747e-03, -1.8369e-02, -3.7954e-03,\n",
              "                      -9.1116e-03,  8.2030e-03, -1.2718e-02,  1.2471e-03, -1.1099e-02,\n",
              "                      -7.0170e-03, -1.2410e-02,  1.1164e-03, -2.7920e-03, -1.4738e-02,\n",
              "                       1.8492e-03, -1.0134e-02, -1.3059e-02,  9.7056e-03,  8.0514e-03,\n",
              "                       4.8457e-04,  9.4198e-03,  5.2996e-03,  1.6217e-02, -1.1022e-02,\n",
              "                      -1.5215e-02, -1.7134e-02,  1.1622e-02,  1.1803e-02, -1.6373e-02,\n",
              "                       1.2082e-02, -4.0744e-03, -8.4192e-03,  1.2189e-02, -3.9360e-03,\n",
              "                      -9.3119e-03,  2.9969e-03,  1.0234e-02, -1.4006e-02, -1.1938e-02,\n",
              "                      -1.1910e-02,  1.6026e-02,  6.0756e-03, -1.0758e-02,  1.8078e-02,\n",
              "                      -3.0069e-03,  1.6406e-02,  1.1244e-02,  3.2860e-03, -3.9761e-03,\n",
              "                       2.1145e-03, -2.4717e-03, -1.5469e-02, -9.4210e-03,  4.3736e-03,\n",
              "                       5.6239e-03,  9.6697e-03,  1.8387e-02, -1.0061e-02, -1.0628e-02,\n",
              "                       4.4887e-03,  1.1656e-04,  5.0060e-03, -1.8112e-03, -2.0628e-03,\n",
              "                      -8.9231e-03, -2.8393e-03,  1.2719e-02,  1.4254e-02, -1.4835e-02,\n",
              "                       3.1519e-03, -4.5413e-03,  6.2147e-03,  1.1242e-02,  8.4619e-03,\n",
              "                      -1.6235e-02, -9.8955e-03, -1.4129e-02, -1.2147e-02,  7.3852e-03,\n",
              "                       5.8532e-04, -2.0838e-02,  1.4569e-02, -1.3726e-02, -5.7444e-03,\n",
              "                      -4.6498e-03, -1.2653e-02,  8.7805e-03,  1.5812e-02,  4.2510e-03,\n",
              "                       3.2197e-03,  2.3808e-03, -1.4696e-02, -1.2969e-02,  2.1009e-04,\n",
              "                      -1.6283e-02,  5.8447e-04,  6.6565e-03, -6.0314e-03,  1.3001e-03,\n",
              "                      -6.3259e-03,  1.3075e-02, -1.3591e-02,  1.7750e-02,  4.9504e-03,\n",
              "                      -4.2734e-03, -1.1485e-02,  1.4081e-02,  1.2222e-02,  4.1274e-03,\n",
              "                       5.0460e-03, -2.9767e-03, -4.4612e-03, -1.1484e-02, -6.1129e-03,\n",
              "                      -8.5367e-03, -1.1255e-02, -1.6011e-02, -6.8096e-03,  4.4055e-03,\n",
              "                       1.4982e-02, -9.5693e-03, -6.6555e-03, -9.5065e-03, -1.4918e-02,\n",
              "                      -1.1794e-03,  2.9279e-03,  1.7250e-02, -1.4754e-02, -1.4910e-02,\n",
              "                       1.2390e-03,  7.6607e-03, -1.2865e-03,  7.2206e-04, -5.8496e-03,\n",
              "                       3.6294e-03,  1.4497e-02, -8.4343e-03,  1.4119e-02,  7.0035e-03,\n",
              "                       1.4409e-02,  4.8647e-03,  1.4423e-03, -7.7569e-03,  3.9838e-03,\n",
              "                      -4.0867e-04, -7.3516e-03, -1.1763e-02, -5.9681e-03,  5.1105e-03,\n",
              "                      -1.4101e-02,  4.1353e-03, -1.4013e-02, -1.8104e-02,  1.9664e-04,\n",
              "                      -6.0784e-03,  1.2958e-02, -1.1819e-04, -9.5025e-03, -9.4130e-03,\n",
              "                       7.7872e-03,  1.8540e-02, -1.1077e-02, -1.4207e-02, -7.7066e-03,\n",
              "                       9.0405e-03,  1.1309e-03,  1.1359e-02,  1.4609e-02,  3.9111e-03,\n",
              "                       1.7924e-02, -1.5576e-02,  8.3626e-03, -8.0276e-05, -8.8887e-03,\n",
              "                       7.6155e-03, -1.6176e-02,  9.7776e-03, -8.7106e-03,  1.5736e-02,\n",
              "                       4.5762e-03,  8.0869e-04,  7.5247e-04,  9.0575e-03,  1.4407e-02,\n",
              "                       4.9214e-03, -1.4790e-02,  2.8804e-03, -1.6477e-02,  1.3771e-02,\n",
              "                       5.5366e-03, -1.0808e-02,  8.0510e-03,  4.6658e-03, -1.5214e-02,\n",
              "                       1.0488e-02, -1.5309e-02,  1.5960e-02, -1.0022e-02,  1.5073e-02,\n",
              "                       1.1175e-03, -1.3876e-03, -4.5767e-03, -2.7392e-03,  4.0819e-03,\n",
              "                       6.1274e-03,  9.2590e-03, -6.4362e-03, -8.2455e-03, -1.0936e-02,\n",
              "                      -1.1331e-02,  3.8740e-03, -4.6777e-03,  1.1792e-02,  1.4599e-02,\n",
              "                      -6.2586e-03, -8.9636e-03, -2.7124e-03,  1.0616e-02, -8.5537e-03,\n",
              "                       1.4428e-02,  1.0293e-02, -1.1730e-02,  1.3833e-02, -3.0755e-03,\n",
              "                      -1.0873e-02, -7.7348e-03, -8.9591e-03,  1.4053e-02,  1.4470e-04,\n",
              "                       7.8584e-03, -1.2605e-02,  1.2760e-02, -1.2865e-04, -1.5075e-02,\n",
              "                       1.5339e-02, -1.6614e-02, -1.7907e-02,  1.3227e-02,  1.3127e-02,\n",
              "                      -1.6387e-03, -5.5224e-03,  1.6619e-02, -2.0021e-03,  1.5404e-02,\n",
              "                       1.5511e-02, -1.4151e-02, -1.5935e-03,  8.9108e-03, -5.9778e-03,\n",
              "                      -1.3530e-02, -1.3894e-02,  1.7236e-02, -1.0221e-02,  7.1137e-03,\n",
              "                       1.0351e-02,  1.2146e-02,  1.5878e-02, -1.4307e-02,  9.7515e-05,\n",
              "                      -4.5141e-03,  8.9118e-04, -1.0126e-03, -5.5798e-03, -1.3898e-03,\n",
              "                      -1.5409e-02, -6.7134e-03, -1.5101e-03,  8.0588e-03, -7.4821e-03,\n",
              "                       1.0982e-02, -3.6978e-03,  8.9668e-03,  1.3781e-03, -1.4377e-02,\n",
              "                      -8.3124e-03, -1.2962e-02,  8.3154e-03, -1.6236e-02,  1.2597e-02,\n",
              "                       1.0438e-02, -6.1052e-03,  3.2685e-03, -1.3705e-02, -4.7467e-03,\n",
              "                       6.3751e-03,  1.6527e-02, -1.4030e-02, -1.5246e-02, -7.4690e-03,\n",
              "                       1.1724e-02, -1.2002e-02, -1.5147e-02, -1.0162e-02,  1.6980e-02,\n",
              "                       7.4471e-03, -1.6418e-02,  1.2748e-02,  8.9848e-03, -1.0482e-03,\n",
              "                       1.4960e-02, -1.5305e-02,  1.2894e-02, -1.2252e-02, -1.4768e-02,\n",
              "                      -3.4125e-03,  1.0632e-02, -1.2081e-02,  2.1282e-03,  5.3255e-04,\n",
              "                       1.5184e-02, -1.5890e-02,  1.5103e-02, -6.8606e-03,  1.8086e-02,\n",
              "                      -7.7401e-03,  1.7638e-02,  1.6337e-02,  1.5279e-03, -1.1101e-02,\n",
              "                      -1.2592e-02,  4.6547e-03,  3.3560e-03,  1.0634e-02,  5.4877e-03,\n",
              "                       1.0858e-02, -8.8124e-05, -4.1200e-03, -1.5214e-02, -2.2485e-03,\n",
              "                      -4.3612e-03,  1.4835e-03, -1.4191e-02, -9.6921e-03, -7.7594e-03,\n",
              "                      -1.3909e-02, -3.7284e-03,  3.6982e-04, -1.5953e-03, -5.3823e-03,\n",
              "                       6.5611e-03,  6.1820e-04, -1.4487e-02, -8.4954e-03,  1.3880e-02,\n",
              "                       9.5997e-03,  4.6058e-03, -1.5785e-02, -1.8034e-02,  1.1685e-02,\n",
              "                      -1.1480e-02, -2.2080e-03, -3.5061e-03, -2.2045e-03,  6.6558e-03,\n",
              "                       7.9548e-03, -1.8398e-02,  4.1357e-03,  9.5148e-03,  1.4430e-03,\n",
              "                       1.0163e-02,  7.3355e-03, -5.0109e-04,  7.1564e-04, -2.0949e-02,\n",
              "                       1.3630e-02,  1.7207e-03, -2.9604e-03,  3.6481e-03,  6.5673e-03,\n",
              "                       1.4420e-02, -3.3543e-03,  8.3258e-03, -1.4367e-02,  1.4133e-02,\n",
              "                      -1.0517e-02,  1.3409e-03,  7.1091e-03, -3.2482e-03,  1.1681e-02,\n",
              "                       2.1712e-03, -9.9838e-03, -1.4577e-02,  6.9917e-03, -1.4470e-02,\n",
              "                       1.4367e-02, -1.4887e-02,  2.3990e-03, -1.0712e-02,  1.6521e-02,\n",
              "                      -6.8616e-03, -1.2275e-02, -1.1388e-02,  8.8385e-03, -1.4114e-03,\n",
              "                       6.3098e-03,  3.5758e-03,  7.7076e-03,  6.1462e-03,  1.3660e-02,\n",
              "                      -8.1631e-03,  7.6946e-04, -7.7871e-03,  8.7985e-03, -2.3552e-03,\n",
              "                       1.1063e-02, -1.4242e-02, -1.6368e-02, -6.0204e-03, -1.0732e-02,\n",
              "                      -1.6853e-02,  1.1627e-02, -8.2753e-03, -4.2440e-03,  1.3400e-02,\n",
              "                       1.0393e-02, -1.1605e-03,  1.1595e-02,  1.5905e-02, -7.2266e-03,\n",
              "                      -7.2795e-03,  1.8499e-03, -9.8795e-03, -2.0618e-03,  1.5901e-02,\n",
              "                       1.0779e-02, -1.0426e-02,  7.0126e-03,  1.8791e-02, -6.1309e-03,\n",
              "                      -8.2327e-03,  1.3374e-02,  1.3162e-02, -2.6833e-03, -9.7411e-03,\n",
              "                       1.5836e-02,  1.1211e-02, -8.8329e-03, -1.1117e-02, -2.6380e-03,\n",
              "                       1.0561e-02,  1.0221e-03, -1.4694e-02,  1.7949e-02, -2.3598e-03,\n",
              "                       8.1683e-03,  7.3779e-03, -1.3729e-02, -1.4124e-02, -8.2067e-03,\n",
              "                      -7.3329e-03,  1.4772e-02,  2.2377e-03, -1.5356e-02, -6.3121e-03,\n",
              "                       3.4633e-04, -4.7732e-03, -1.6021e-02, -1.3408e-02, -1.7305e-02,\n",
              "                       1.2200e-02,  4.3101e-03, -1.3356e-02,  1.2605e-02,  8.0960e-03,\n",
              "                       2.2095e-03, -1.2371e-02,  6.9613e-04,  1.2759e-02,  7.7870e-03,\n",
              "                      -1.4876e-03, -1.5965e-03, -8.1408e-03, -1.1146e-03, -1.0824e-03,\n",
              "                      -1.9001e-02,  1.5774e-02, -1.5023e-04, -9.9671e-03, -1.4134e-02,\n",
              "                      -3.2435e-03,  8.0435e-03, -6.9505e-03,  1.7651e-02, -5.7000e-04,\n",
              "                      -7.7392e-03, -2.8466e-03, -2.6033e-03,  1.7053e-02,  1.4695e-02,\n",
              "                      -1.4514e-02,  1.0639e-03, -7.8960e-03,  4.5374e-03, -3.0159e-03,\n",
              "                      -1.2681e-02, -2.2325e-03, -1.4413e-02,  1.8763e-02,  2.9015e-03,\n",
              "                      -6.3104e-03, -1.0163e-02,  1.5884e-02,  8.9470e-03, -1.3901e-02,\n",
              "                      -1.2348e-02, -6.4517e-03, -3.6908e-03,  1.7783e-02, -3.2910e-03,\n",
              "                      -3.7802e-03,  9.7545e-03, -2.9059e-03, -9.9470e-03,  1.5539e-02,\n",
              "                       1.3223e-02, -1.6327e-02,  1.6160e-02, -1.4822e-02, -7.2331e-03,\n",
              "                       1.1537e-02, -8.7891e-03, -7.3259e-03,  1.1939e-02,  1.2382e-03,\n",
              "                       1.1589e-02, -9.5719e-03,  8.3443e-03,  1.0927e-02, -4.4157e-03,\n",
              "                      -1.3300e-02, -8.6788e-03,  5.3150e-04, -1.5521e-02, -1.0158e-02,\n",
              "                      -1.9010e-02, -2.8734e-03,  7.7263e-03,  1.6409e-02,  1.3318e-02,\n",
              "                       5.6487e-03,  3.2104e-03, -1.5807e-02,  1.7346e-03,  6.1440e-03,\n",
              "                       1.6387e-02,  1.4715e-02,  4.6270e-03, -1.5095e-02,  1.6641e-03,\n",
              "                      -9.3362e-03, -7.9283e-03, -6.4354e-03,  1.5965e-03, -1.4760e-02,\n",
              "                       1.6353e-02,  1.2062e-02,  8.7295e-03,  1.3775e-02, -1.6755e-02,\n",
              "                       1.1391e-02,  1.7381e-03, -6.7637e-03,  1.4848e-02, -7.1473e-03,\n",
              "                      -1.2190e-02,  7.5471e-03,  2.3487e-03, -6.9264e-03,  2.5628e-03])),\n",
              "             ('fc2.weight',\n",
              "              tensor([[ 0.0107,  0.0220, -0.0367,  ..., -0.0360, -0.0016, -0.0300],\n",
              "                      [-0.0118,  0.0037,  0.0180,  ..., -0.0328,  0.0418,  0.0455],\n",
              "                      [ 0.0376, -0.0583,  0.0272,  ...,  0.0123,  0.0334, -0.0341],\n",
              "                      ...,\n",
              "                      [ 0.0138,  0.0341, -0.0501,  ..., -0.0078, -0.0458,  0.0227],\n",
              "                      [ 0.0144, -0.0115, -0.0127,  ..., -0.0011, -0.0090,  0.0304],\n",
              "                      [ 0.0067,  0.0056, -0.0089,  ..., -0.0251, -0.0229, -0.0259]])),\n",
              "             ('fc2.bias',\n",
              "              tensor([-0.0293,  0.0657,  0.0081,  0.0012,  0.0136,  0.0305,  0.0007,  0.0094,\n",
              "                      -0.0411, -0.0271]))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIJD0a0WZesN",
        "colab_type": "text"
      },
      "source": [
        "To load the model weights, we can instante a new object of the class `MnistModel`, and use the `.load_state_dict` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j31tDT2ZesN",
        "colab_type": "code",
        "colab": {},
        "outputId": "d9137e47-dfac-4ab0-9311-3032d6091d17"
      },
      "source": [
        "model2 = MnistModel()\n",
        "model2.load_state_dict(torch.load('mnist-logistic.pth'))\n",
        "model2.state_dict()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('linear.weight',\n",
              "              tensor([[ 0.0251,  0.0241, -0.0165,  ..., -0.0104, -0.0195,  0.0201],\n",
              "                      [-0.0234,  0.0099,  0.0338,  ..., -0.0203, -0.0133,  0.0212],\n",
              "                      [ 0.0063, -0.0131,  0.0202,  ..., -0.0164,  0.0221,  0.0011],\n",
              "                      ...,\n",
              "                      [-0.0079,  0.0126, -0.0063,  ..., -0.0049, -0.0159,  0.0094],\n",
              "                      [-0.0264, -0.0351,  0.0151,  ...,  0.0070, -0.0234, -0.0352],\n",
              "                      [ 0.0140, -0.0059,  0.0071,  ...,  0.0348,  0.0120,  0.0213]])),\n",
              "             ('linear.bias',\n",
              "              tensor([-0.0809,  0.1206, -0.0430, -0.0242, -0.0004,  0.0362,  0.0046,  0.0181,\n",
              "                      -0.0809, -0.0435]))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luMVbt2bZesO",
        "colab_type": "text"
      },
      "source": [
        "Just as a sanity check, let's verify that this model has the same loss and accuracy on the test set as before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGmrPGcTZesO",
        "colab_type": "code",
        "colab": {},
        "outputId": "3dc369c8-61d6-46a8-9cda-b41c53942e37"
      },
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=256)\n",
        "result = evaluate(model2, test_loader)\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'val_loss': 0.5958371162414551, 'val_acc': 0.867382824420929}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4r68b9pZesP",
        "colab_type": "text"
      },
      "source": [
        "## Commit and upload the notebook\n",
        "\n",
        "As a final step, we can save and commit our work using the jovian library. Along with the notebook, we can also attach the weights of our trained model, so that we can use it later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAaJAi6BZesP",
        "colab_type": "code",
        "colab": {},
        "outputId": "969f990a-ce93-42e8-c3d9-54e2b9ca5d91"
      },
      "source": [
        "jovian.commit(project='03-logistic-regression', environment=None, outputs=['mnist-logistic.pth'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[jovian] Attempting to save notebook..\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn3_BsUVZesR",
        "colab_type": "text"
      },
      "source": [
        "## Summary and Further Reading\n",
        "\n",
        "We've created a fairly sophisticated training and evaluation pipeline in this tutorial. Here's a list of the topics we've covered:\n",
        "\n",
        "* Working with images in PyTorch (using the MNIST dataset)\n",
        "* Splitting a dataset into training, validation and test sets\n",
        "* Creating PyTorch models with custom logic by extending the `nn.Module` class\n",
        "* Interpreting model ouputs as probabilities using softmax, and picking predicted labels\n",
        "* Picking a good evaluation metric (accuracy) and loss function (cross entropy) for classification problems\n",
        "* Setting up a training loop that also evaluates the model using the validation set\n",
        "* Testing the model manually on randomly picked examples \n",
        "* Saving and loading model checkpoints to avoid retraining from scratch\n",
        "\n",
        "There's a lot of scope to experiment here, and I encourage you to use the interactive nature of Jupyter to play around with the various parameters. Here are a few ideas:\n",
        "\n",
        "* Try making the validation set smaller or larger, and see how it affects the model.\n",
        "* Try changing the learning rate and see if you can achieve the same accuracy in fewer epochs.\n",
        "* Try changing the batch size. What happens if you use too high a batch size, or too low?\n",
        "* Modify the `fit` function to also track the overall loss and accuracy on the training set, and see how it compares with the validation loss/accuracy. Can you explain why it's lower/higher?\n",
        "* Train with a small subset of the data, and see if you can reach a similar level of accuracy.\n",
        "* Try building a model for a different dataset, such as the [CIFAR10 or CIFAR100 datasets](https://www.cs.toronto.edu/~kriz/cifar.html).\n",
        "\n",
        "Here are some references for further reading:\n",
        "* For a more mathematical treatment, see the popular [Machine Learning](https://www.coursera.org/lecture/machine-learning/classification-wlPeP) course on Coursera. Most of the images used in this tutorial series have been taken from this course.\n",
        "* The training loop defined in this notebook was inspired from [FastAI development notebooks](https://github.com/fastai/fastai_docs/blob/master/dev_nb/001a_nn_basics.ipynb) which contain a wealth of other useful stuff if you can read and understand the code.\n",
        "* For a deep dive into softmax and cross entropy, see [this blog post on DeepNotes](https://deepnotes.io/softmax-crossentropy).\n",
        "\n",
        "\n",
        "With this we complete our discussion of logistic regression, and we're ready to move on to the next topic: *feedforward neural networks*!"
      ]
    }
  ]
}